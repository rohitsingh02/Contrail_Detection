{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "041ac14f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# os.environ['CUDA_VISIBLE_DEVICES'] = '1'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "77e5af39",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import pathlib\n",
    "import gc\n",
    "import pandas as pd\n",
    "import ttach as tta\n",
    "from pathlib import Path\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import cv2 as cv\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "# from tqdm.auto import tqdm\n",
    "from tqdm.notebook import tqdm\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch import optim\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "import torchvision\n",
    "from torchvision import datasets\n",
    "import cv2\n",
    "from torch.cuda import amp\n",
    "\n",
    "import torchvision.transforms as T\n",
    "from torchvision.transforms import Compose, ToTensor, Resize\n",
    "from torchvision.utils import make_grid\n",
    "import optuna\n",
    "\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "import segmentation_models_pytorch as smp\n",
    "import timm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "157ff8d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def seed_everything(seed=42):\n",
    "    '''Sets the seed of the entire notebook so results are the same every time we run.\n",
    "    This is for REPRODUCIBILITY.'''\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "12e6bf9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed_everything(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ddb77d81",
   "metadata": {},
   "outputs": [],
   "source": [
    "folder = \"train\"  # \"validation\"\n",
    "    \n",
    "NTB = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c5654e79",
   "metadata": {},
   "outputs": [],
   "source": [
    "CFGS = [ \n",
    "    \n",
    "    {\n",
    "        'model_name': 'Unet++',\n",
    "        'backbone': 'tf_efficientnet_b7_ns',\n",
    "        'img_size': [512, 512],\n",
    "        'num_classes': 1,\n",
    "        'model_pth':  '/home/rohits/pv1/contrail_01/output/nirjhar/qishentrialv2fpn512_tf_efficientnet_b7_ns_best_epochcv650lb675-00.bin',\n",
    "        'threshold': 0.62, #0.24,\n",
    "        'call_sign': \"nir_01\",\n",
    "        'tta': True\n",
    "    },\n",
    "\n",
    "    {\n",
    "        'model_name': 'Unet++',\n",
    "        'backbone': 'tf_efficientnet_b7_ns',\n",
    "        'img_size': [512, 512],\n",
    "        'num_classes': 1,\n",
    "        'model_pth':  '/home/rohits/pv1/contrail_01/output/nirjhar/qishentrialv512unetplus_tf_efficientnet_b7_ns_best_epochstage2cv669-00.bin',\n",
    "        'threshold': 0.62, #0.24,\n",
    "        'call_sign': \"nir_02\", \n",
    "        'tta': True\n",
    "    },\n",
    "    {\n",
    "        'model_name': 'Unet',\n",
    "        'backbone': 'eca_nfnet_l1',\n",
    "        'img_size': [512, 512],\n",
    "        'num_classes': 1,\n",
    "        'model_pth':  '/home/rohits/pv1/contrail_01/output/nirjhar/unetplusecarnf01_eca_nfnet_l1_best_epochstage2cv656-00.bin',\n",
    "        'threshold': 0.62, #0.24,\n",
    "        'call_sign': \"nir_03\",\n",
    "        'tta': True\n",
    "    },\n",
    "    {\n",
    "    'model_name': 'Unet++',\n",
    "        'backbone': 'tf_efficientnet_b8',\n",
    "        'img_size': [512, 512],\n",
    "        'num_classes': 1,\n",
    "        'model_pth':  '/home/rohits/pv1/Contrail_Detection/output/nirjhar/effb8modelv2fold0_tf_efficientnet_b8_best_epochstage2-00.bin',\n",
    "        'threshold': 0.79,\n",
    "        'call_sign': \"nir_04\", \n",
    "        'tta': True\n",
    "    },    \n",
    "\n",
    "    {\n",
    "        'model_name': 'Unet',\n",
    "        'backbone': 'efficientnet-b7',\n",
    "        'img_size': [256, 256],\n",
    "        'num_classes': 1,\n",
    "        'model_pth':  '/home/rohits/pv1/Contrail_Detection/output/exp_01/Unet/efficientnet-b7-256/checkpoint_dice_fold3.pth',\n",
    "        'threshold': 0.24, #0.24,\n",
    "        'call_sign': \"roh_06\",\n",
    "        'tta': True\n",
    "    }, \n",
    "    {\n",
    "        'model_name': 'Unet',\n",
    "        'backbone': 'efficientnet-b7',\n",
    "        'img_size': [256, 256],\n",
    "        'num_classes': 1,\n",
    "        'model_pth':  '/home/rohits/pv1/Contrail_Detection/output/exp_01_s2/Unet/efficientnet-b7-256/checkpoint_dice_fold0.pth',\n",
    "        'threshold': 0.24, #0.24,\n",
    "        'call_sign': \"roh_07\",\n",
    "        'tta': True\n",
    "    },     \n",
    "    {\n",
    "        'model_name': 'Unet',\n",
    "        'backbone': 'efficientnet-b7',\n",
    "        'img_size': [256, 256],\n",
    "        'num_classes': 1,\n",
    "        'model_pth':  '/home/rohits/pv1/Contrail_Detection/output/exp_01_s2/Unet/efficientnet-b7-256/checkpoint_dice_ctrl_fold3.pth',\n",
    "        'threshold': 0.24, #0.24,\n",
    "        'call_sign': \"roh_08\",\n",
    "        'tta': True\n",
    "    },     \n",
    "    {\n",
    "        'model_name': 'Unet',\n",
    "        'backbone': 'efficientnet-b7',\n",
    "        'img_size': [256, 256],\n",
    "        'num_classes': 1,\n",
    "        'model_pth':  '/home/rohits/pv1/Contrail_Detection/output/exp_01_pl/Unet/efficientnet-b7-256/checkpoint_dice_ctrl_fold0.pth',\n",
    "        'threshold': 0.24, #0.24,\n",
    "        'call_sign': \"roh_11\",\n",
    "        'tta': True\n",
    "    }, \n",
    "    \n",
    "    \n",
    "    {\n",
    "        'model_name': 'Unet',\n",
    "        'backbone': 'efficientnet-b7',\n",
    "        'img_size': [256, 256],\n",
    "        'num_classes': 1,\n",
    "        'model_pth':  '/home/rohits/pv1/Contrail_Detection/output/exp_01_pl_s2/Unet/efficientnet-b7-256/checkpoint_dice_fold3.pth',\n",
    "        'threshold': 0.24, #0.24,\n",
    "        'call_sign': \"roh_11\",\n",
    "        'tta': True\n",
    "    }, \n",
    "\n",
    "]\n",
    "\n",
    "ensemple_type = \"No\" #\"No\" #\"mine\"\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2ddaafa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d58a5058",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ContrailDataset:\n",
    "    def __init__(self, df, transform=None):\n",
    "        self.df = df  \n",
    "        self.images = df['image']\n",
    "        self.transform =transform\n",
    "        \n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "        \n",
    "    def __getitem__(self, idx):\n",
    "        image = np.load(\"../../input/\" + self.images[idx]).astype(float)   \n",
    "#         label = np.load(\"../../input\" + self.labels[idx]).astype(float)\n",
    "        \n",
    "        \n",
    "        # label_cls = 1 if label.sum() > 0 else 0\n",
    "        if self.transform :\n",
    "            data = self.transform(image=image)\n",
    "            image  = data['image']\n",
    "            image = np.transpose(image, (2, 0, 1))\n",
    "            \n",
    "        return torch.tensor(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6467d004",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ad837733",
   "metadata": {},
   "outputs": [],
   "source": [
    "import segmentation_models_pytorch as smp\n",
    "import timm\n",
    "n_blocks = 4\n",
    "\n",
    "class TimmSegModel(nn.Module):\n",
    "    def __init__(self, cfg, segtype='unet', pretrained=True):\n",
    "        super(TimmSegModel, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 6, 3, stride=1, padding=1, bias=False)\n",
    "        self.conv2 = nn.Conv2d(6, 12, 3, stride=1, padding=1, bias=False)\n",
    "        self.conv3 = nn.Conv2d(12, 36, 3, stride=1, padding=1, bias=False)\n",
    "        self.mybn1 = nn.BatchNorm2d(6)\n",
    "        self.mybn2 = nn.BatchNorm2d(12)\n",
    "        self.mybn3 = nn.BatchNorm2d(36)     \n",
    "        self.encoder = timm.create_model(\n",
    "            cfg[\"backbone\"],\n",
    "            in_chans=3,\n",
    "            features_only=True,\n",
    "            drop_rate=0.8,\n",
    "            drop_path_rate=0.5,\n",
    "            pretrained=False\n",
    "        )\n",
    "        self.encoder.conv_stem=nn.Conv2d(6, 72, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
    "\n",
    "        self.encoder.blocks[5] = nn.Identity()\n",
    "        self.encoder.blocks[6] = nn.Sequential(\n",
    "            nn.Conv2d(self.encoder.blocks[4][2].conv_pwl.out_channels, 320, 1),\n",
    "            nn.BatchNorm2d(320),\n",
    "            nn.ReLU6(),\n",
    "        )\n",
    "        tr = torch.randn(1,6,64,64)\n",
    "        g = self.encoder(tr)\n",
    "        encoder_channels = [1] + [_.shape[1] for _ in g]\n",
    "        decoder_channels = [256, 128, 64, 32, 16]\n",
    "        if segtype == 'unet':\n",
    "            self.decoder = smp.decoders.unetplusplus.decoder.UnetPlusPlusDecoder(\n",
    "                encoder_channels=encoder_channels[:n_blocks+1],\n",
    "                decoder_channels=decoder_channels[:n_blocks],\n",
    "                n_blocks=n_blocks,\n",
    "            )\n",
    "\n",
    "        self.segmentation_head = nn.Conv2d(decoder_channels[n_blocks-1], cfg['num_classes'], kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
    "\n",
    "    def forward(self,x):\n",
    "        x = F.relu6(self.mybn1(self.conv1(x)))\n",
    "        global_features = [0] + self.encoder(x)[:n_blocks]\n",
    "        seg_features = self.decoder(*global_features)\n",
    "        seg_features = self.segmentation_head(seg_features)\n",
    "        return seg_features\n",
    "    \n",
    "    \n",
    "    \n",
    "def load_model_timmunetplusplus(cfg):\n",
    "    model = TimmSegModel(cfg)\n",
    "    model.load_state_dict(torch.load(cfg['model_pth']))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c621dc34",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fff7d898",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "985b3de5",
   "metadata": {},
   "outputs": [],
   "source": [
    "###TImmunetplusplus model Nirjhar\n",
    "\n",
    "n_blocks = 4\n",
    "\n",
    "class TimmSegModel(nn.Module):\n",
    "    def __init__(self, backbone, cfg, segtype='unet', pretrained=True):\n",
    "        super(TimmSegModel, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 6, 3, stride=1, padding=1, bias=False)\n",
    "        self.conv2 = nn.Conv2d(6, 12, 3, stride=1, padding=1, bias=False)\n",
    "        self.conv3 = nn.Conv2d(12, 36, 3, stride=1, padding=1, bias=False)\n",
    "        self.mybn1 = nn.BatchNorm2d(6)\n",
    "        self.mybn2 = nn.BatchNorm2d(12)\n",
    "        self.mybn3 = nn.BatchNorm2d(36)     \n",
    "        self.encoder = timm.create_model(\n",
    "            backbone,\n",
    "            in_chans=3,\n",
    "            features_only=True,\n",
    "            drop_rate=0.8,\n",
    "            drop_path_rate=0.5,\n",
    "            pretrained=False\n",
    "        )\n",
    "        self.encoder.conv_stem=nn.Conv2d(6, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
    "\n",
    "        self.encoder.blocks[5] = nn.Identity()\n",
    "        self.encoder.blocks[6] = nn.Sequential(\n",
    "            nn.Conv2d(self.encoder.blocks[4][2].conv_pwl.out_channels, 320, 1),\n",
    "            nn.BatchNorm2d(320),\n",
    "            nn.ReLU6(),\n",
    "        )\n",
    "        tr = torch.randn(1,6,64,64)\n",
    "        g = self.encoder(tr)\n",
    "        encoder_channels = [1] + [_.shape[1] for _ in g]\n",
    "        decoder_channels = [256, 128, 64, 32, 16]\n",
    "        if segtype == 'unet':\n",
    "            self.decoder = smp.decoders.unetplusplus.decoder.UnetPlusPlusDecoder(\n",
    "                encoder_channels=encoder_channels[:n_blocks+1],\n",
    "                decoder_channels=decoder_channels[:n_blocks],\n",
    "                n_blocks=n_blocks,\n",
    "            )\n",
    "\n",
    "        self.segmentation_head = nn.Conv2d(\n",
    "            decoder_channels[n_blocks-1],\n",
    "            cfg[\"num_classes\"], \n",
    "            kernel_size=(3, 3),\n",
    "            stride=(1, 1), \n",
    "            padding=(1, 1)\n",
    "        )\n",
    "\n",
    "    def forward(self,x):\n",
    "        x = F.relu6(self.mybn1(self.conv1(x)))\n",
    "        global_features = [0] + self.encoder(x)[:n_blocks]\n",
    "        seg_features = self.decoder(*global_features)\n",
    "        seg_features = self.segmentation_head(seg_features)\n",
    "        return seg_features\n",
    "    \n",
    "\n",
    "#path='./exp/baselinev2/qishentrialv2_tf_efficientnet_b7_ns_last_epoch-00.bin'\n",
    "\n",
    "def build_model_timmunetplus(backbone, cfg):\n",
    "    model = TimmSegModel(backbone, cfg)\n",
    "    return model\n",
    "\n",
    "def load_model_timmunetplus(path, backbone, cfg):\n",
    "    model = build_model_timmunetplus(backbone, cfg)\n",
    "    model.load_state_dict(torch.load(path))\n",
    "    return model\n",
    "\n",
    "\n",
    "#### Model 2 Nirjhar\n",
    "\n",
    "n_blocks =4\n",
    "class TimmSegModel2(nn.Module):\n",
    "    def __init__(self, backbone, segtype='unet', pretrained=True):\n",
    "        super(TimmSegModel2, self).__init__()\n",
    "\n",
    "        self.encoder = timm.create_model(\n",
    "            backbone,\n",
    "            in_chans=3,\n",
    "            features_only=True,\n",
    "            drop_rate=0.5,\n",
    "            pretrained=False\n",
    "        )\n",
    "        g = self.encoder(torch.rand(1, 3, 128, 128))\n",
    "        encoder_channels = [1] + [_.shape[1] for _ in g]\n",
    "        decoder_channels = [256, 128, 64, 32, 16]\n",
    "        if segtype == 'unet':\n",
    "            self.decoder = smp.decoders.unetplusplus.decoder.UnetPlusPlusDecoder(\n",
    "                encoder_channels=encoder_channels[:n_blocks+1],\n",
    "                decoder_channels=decoder_channels[:n_blocks],\n",
    "                n_blocks=n_blocks,\n",
    "            )\n",
    "\n",
    "        self.segmentation_head = nn.Sequential(\n",
    "            nn.Conv2d(decoder_channels[n_blocks-1], 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)),\n",
    "            nn.UpsamplingBilinear2d(scale_factor=1))\n",
    "\n",
    "    def forward(self,x):\n",
    "        global_features = [0] + self.encoder(x)[:n_blocks]\n",
    "        seg_features = self.decoder(*global_features)\n",
    "        seg_features = self.segmentation_head(seg_features)\n",
    "        return seg_features\n",
    "    \n",
    "\n",
    "\n",
    "def build_model(backbone):\n",
    "    model = TimmSegModel2(backbone, segtype='unet')\n",
    "    return model\n",
    "\n",
    "def load_model(path,backbone):\n",
    "    model = build_model(backbone)\n",
    "    model.load_state_dict(torch.load(path))\n",
    "    return model\n",
    "\n",
    "\n",
    "##################\n",
    "\n",
    "n_blocks = 4\n",
    "\n",
    "class TimmSegModel3(nn.Module):\n",
    "    def __init__(self, cfg, segtype='unet', pretrained=True):\n",
    "        super(TimmSegModel3, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 6, 3, stride=1, padding=1, bias=False)\n",
    "        self.conv2 = nn.Conv2d(6, 12, 3, stride=1, padding=1, bias=False)\n",
    "        self.conv3 = nn.Conv2d(12, 36, 3, stride=1, padding=1, bias=False)\n",
    "        self.mybn1 = nn.BatchNorm2d(6)\n",
    "        self.mybn2 = nn.BatchNorm2d(12)\n",
    "        self.mybn3 = nn.BatchNorm2d(36)     \n",
    "        self.encoder = timm.create_model(\n",
    "            cfg[\"backbone\"],\n",
    "            in_chans=3,\n",
    "            features_only=True,\n",
    "            drop_rate=0.8,\n",
    "            drop_path_rate=0.5,\n",
    "            pretrained=False\n",
    "        )\n",
    "        self.encoder.conv_stem=nn.Conv2d(6, 72, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
    "\n",
    "        self.encoder.blocks[5] = nn.Identity()\n",
    "        self.encoder.blocks[6] = nn.Sequential(\n",
    "            nn.Conv2d(self.encoder.blocks[4][2].conv_pwl.out_channels, 320, 1),\n",
    "            nn.BatchNorm2d(320),\n",
    "            nn.ReLU6(),\n",
    "        )\n",
    "        tr = torch.randn(1,6,64,64)\n",
    "        g = self.encoder(tr)\n",
    "        encoder_channels = [1] + [_.shape[1] for _ in g]\n",
    "        decoder_channels = [256, 128, 64, 32, 16]\n",
    "        if segtype == 'unet':\n",
    "            self.decoder = smp.decoders.unetplusplus.decoder.UnetPlusPlusDecoder(\n",
    "                encoder_channels=encoder_channels[:n_blocks+1],\n",
    "                decoder_channels=decoder_channels[:n_blocks],\n",
    "                n_blocks=n_blocks,\n",
    "            )\n",
    "\n",
    "        self.segmentation_head = nn.Conv2d(decoder_channels[n_blocks-1], cfg['num_classes'], kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
    "\n",
    "    def forward(self,x):\n",
    "        x = F.relu6(self.mybn1(self.conv1(x)))\n",
    "        global_features = [0] + self.encoder(x)[:n_blocks]\n",
    "        seg_features = self.decoder(*global_features)\n",
    "        seg_features = self.segmentation_head(seg_features)\n",
    "        return seg_features\n",
    "    \n",
    "    \n",
    "    \n",
    "def load_model3(cfg):\n",
    "    model = TimmSegModel3(cfg)\n",
    "    model.load_state_dict(torch.load(cfg['model_pth']))\n",
    "    return model\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "## Rohit Model \n",
    "class Net(nn.Module):\n",
    "    def __init__(self, cfg):\n",
    "        super().__init__()\n",
    "        self.cfg = cfg\n",
    "        \n",
    "        self.model = smp.Unet(\n",
    "            encoder_name=cfg[\"backbone\"],     \n",
    "            encoder_weights=None,   \n",
    "            in_channels=3,  \n",
    "            classes=cfg[\"num_classes\"],\n",
    "            activation=None\n",
    "        )\n",
    "        \n",
    "    \n",
    "    def forward(self, inputs):\n",
    "        mask = self.model(inputs)\n",
    "        return mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "07bfce0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dice_coef(y_true, y_pred, thr=0.5, epsilon=1e-6):\n",
    "    y_true = y_true.to(torch.float32)\n",
    "    y_pred = (y_pred>thr).to(torch.float32)\n",
    "    inter = (y_true*y_pred).sum()\n",
    "    den = y_true.sum() + y_pred.sum()\n",
    "    dice = ((2*inter+epsilon)/(den+epsilon)).mean()\n",
    "    \n",
    "    return dice\n",
    "\n",
    "\n",
    "def get_transform(img_size):\n",
    "    transform = A.Compose([\n",
    "        A.Resize(*img_size, interpolation=cv2.INTER_NEAREST),\n",
    "    ], p=1.0)\n",
    "    return transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23ec1308",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "67a16803",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {'w1': 0.026130564275158946,\n",
    " 'w2': 0.9456225644729294,\n",
    " 'w3': 0.977118766928013,\n",
    " 'w4': 0.4122243077816452,\n",
    " 'w5': 0.07925478207938379,\n",
    " 'w6': 0.06900567964478133,\n",
    " 'w7': 0.8020704404435675,\n",
    " 'w8': 0.34190685300944035,\n",
    " 'w9': 0.17518538289485933}\n",
    "\n",
    "def weighted_ensemble(params, final_preds):    \n",
    "    for index, val in enumerate(params.keys()):\n",
    "        if index == 0:\n",
    "            preds = params[val]*final_preds[0]\n",
    "        else:\n",
    "            preds += params[val]*final_preds[index]\n",
    "    \n",
    "    param_sum = 0\n",
    "    for key, val in params.items():\n",
    "        param_sum += val\n",
    "\n",
    "    preds = preds/param_sum\n",
    "    return preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "01378f87",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_df = pd.read_csv(f'../../input/pseudo/{folder}_data_{NTB}.csv') \n",
    "\n",
    "\n",
    "# final_preds = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "54b3fef2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image</th>\n",
       "      <th>label</th>\n",
       "      <th>fold</th>\n",
       "      <th>id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>/pseudo/train_data_5/1284412112608546821/image...</td>\n",
       "      <td>/pseudo/train_data_5/1284412112608546821/label...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1284412112608546821</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>/pseudo/train_data_5/7457695218848685981/image...</td>\n",
       "      <td>/pseudo/train_data_5/7457695218848685981/label...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7457695218848685981</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>/pseudo/train_data_5/836236084461732921/image.npy</td>\n",
       "      <td>/pseudo/train_data_5/836236084461732921/label.npy</td>\n",
       "      <td>1.0</td>\n",
       "      <td>836236084461732921</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>/pseudo/train_data_5/7829917977180135058/image...</td>\n",
       "      <td>/pseudo/train_data_5/7829917977180135058/label...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>7829917977180135058</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>/pseudo/train_data_5/5319255125658459358/image...</td>\n",
       "      <td>/pseudo/train_data_5/5319255125658459358/label...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5319255125658459358</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20524</th>\n",
       "      <td>/pseudo/train_data_5/8443915190215904823/image...</td>\n",
       "      <td>/pseudo/train_data_5/8443915190215904823/label...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>8443915190215904823</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20525</th>\n",
       "      <td>/pseudo/train_data_5/8495643844280686935/image...</td>\n",
       "      <td>/pseudo/train_data_5/8495643844280686935/label...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>8495643844280686935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20526</th>\n",
       "      <td>/pseudo/train_data_5/856381910009426679/image.npy</td>\n",
       "      <td>/pseudo/train_data_5/856381910009426679/label.npy</td>\n",
       "      <td>2.0</td>\n",
       "      <td>856381910009426679</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20527</th>\n",
       "      <td>/pseudo/train_data_5/3751790308836191485/image...</td>\n",
       "      <td>/pseudo/train_data_5/3751790308836191485/label...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3751790308836191485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20528</th>\n",
       "      <td>/pseudo/train_data_5/3682248240277515748/image...</td>\n",
       "      <td>/pseudo/train_data_5/3682248240277515748/label...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3682248240277515748</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20529 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   image  \\\n",
       "0      /pseudo/train_data_5/1284412112608546821/image...   \n",
       "1      /pseudo/train_data_5/7457695218848685981/image...   \n",
       "2      /pseudo/train_data_5/836236084461732921/image.npy   \n",
       "3      /pseudo/train_data_5/7829917977180135058/image...   \n",
       "4      /pseudo/train_data_5/5319255125658459358/image...   \n",
       "...                                                  ...   \n",
       "20524  /pseudo/train_data_5/8443915190215904823/image...   \n",
       "20525  /pseudo/train_data_5/8495643844280686935/image...   \n",
       "20526  /pseudo/train_data_5/856381910009426679/image.npy   \n",
       "20527  /pseudo/train_data_5/3751790308836191485/image...   \n",
       "20528  /pseudo/train_data_5/3682248240277515748/image...   \n",
       "\n",
       "                                                   label  fold  \\\n",
       "0      /pseudo/train_data_5/1284412112608546821/label...   4.0   \n",
       "1      /pseudo/train_data_5/7457695218848685981/label...   1.0   \n",
       "2      /pseudo/train_data_5/836236084461732921/label.npy   1.0   \n",
       "3      /pseudo/train_data_5/7829917977180135058/label...   4.0   \n",
       "4      /pseudo/train_data_5/5319255125658459358/label...   3.0   \n",
       "...                                                  ...   ...   \n",
       "20524  /pseudo/train_data_5/8443915190215904823/label...   3.0   \n",
       "20525  /pseudo/train_data_5/8495643844280686935/label...   2.0   \n",
       "20526  /pseudo/train_data_5/856381910009426679/label.npy   2.0   \n",
       "20527  /pseudo/train_data_5/3751790308836191485/label...   0.0   \n",
       "20528  /pseudo/train_data_5/3682248240277515748/label...   3.0   \n",
       "\n",
       "                        id  \n",
       "0      1284412112608546821  \n",
       "1      7457695218848685981  \n",
       "2       836236084461732921  \n",
       "3      7829917977180135058  \n",
       "4      5319255125658459358  \n",
       "...                    ...  \n",
       "20524  8443915190215904823  \n",
       "20525  8495643844280686935  \n",
       "20526   856381910009426679  \n",
       "20527  3751790308836191485  \n",
       "20528  3682248240277515748  \n",
       "\n",
       "[20529 rows x 4 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "646ce6cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'model_name': 'Unet++', 'backbone': 'tf_efficientnet_b7_ns', 'img_size': [512, 512], 'num_classes': 1, 'model_pth': '/home/rohits/pv1/contrail_01/output/nirjhar/qishentrialv2fpn512_tf_efficientnet_b7_ns_best_epochcv650lb675-00.bin', 'threshold': 0.62, 'call_sign': 'nir_01', 'tta': True}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7780533fa89840f7bdfacddd3594637c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/642 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'model_name': 'Unet++', 'backbone': 'tf_efficientnet_b7_ns', 'img_size': [512, 512], 'num_classes': 1, 'model_pth': '/home/rohits/pv1/contrail_01/output/nirjhar/qishentrialv512unetplus_tf_efficientnet_b7_ns_best_epochstage2cv669-00.bin', 'threshold': 0.62, 'call_sign': 'nir_02', 'tta': True}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ceef21aa186346abb75476583708a3e9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/642 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'model_name': 'Unet', 'backbone': 'eca_nfnet_l1', 'img_size': [512, 512], 'num_classes': 1, 'model_pth': '/home/rohits/pv1/contrail_01/output/nirjhar/unetplusecarnf01_eca_nfnet_l1_best_epochstage2cv656-00.bin', 'threshold': 0.62, 'call_sign': 'nir_03', 'tta': True}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "56fba94c2c5e4af3b572c4408c4f2050",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/642 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'model_name': 'Unet++', 'backbone': 'tf_efficientnet_b8', 'img_size': [512, 512], 'num_classes': 1, 'model_pth': '/home/rohits/pv1/Contrail_Detection/output/nirjhar/effb8modelv2fold0_tf_efficientnet_b8_best_epochstage2-00.bin', 'threshold': 0.79, 'call_sign': 'nir_04', 'tta': True}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bfadb01b4fd8482dba66b9d29447b949",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/642 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'model_name': 'Unet', 'backbone': 'efficientnet-b7', 'img_size': [256, 256], 'num_classes': 1, 'model_pth': '/home/rohits/pv1/Contrail_Detection/output/exp_01/Unet/efficientnet-b7-256/checkpoint_dice_fold3.pth', 'threshold': 0.24, 'call_sign': 'roh_06', 'tta': True}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8e14e26549ee4a24a6adc3571e0edb77",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/642 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'model_name': 'Unet', 'backbone': 'efficientnet-b7', 'img_size': [256, 256], 'num_classes': 1, 'model_pth': '/home/rohits/pv1/Contrail_Detection/output/exp_01_s2/Unet/efficientnet-b7-256/checkpoint_dice_fold0.pth', 'threshold': 0.24, 'call_sign': 'roh_07', 'tta': True}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ae8edc443d984660aeedb07b6db9c02a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/642 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'model_name': 'Unet', 'backbone': 'efficientnet-b7', 'img_size': [256, 256], 'num_classes': 1, 'model_pth': '/home/rohits/pv1/Contrail_Detection/output/exp_01_s2/Unet/efficientnet-b7-256/checkpoint_dice_ctrl_fold3.pth', 'threshold': 0.24, 'call_sign': 'roh_08', 'tta': True}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "475aed19938149be8fa5e851e23ade74",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/642 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'model_name': 'Unet', 'backbone': 'efficientnet-b7', 'img_size': [256, 256], 'num_classes': 1, 'model_pth': '/home/rohits/pv1/Contrail_Detection/output/exp_01_pl/Unet/efficientnet-b7-256/checkpoint_dice_ctrl_fold0.pth', 'threshold': 0.24, 'call_sign': 'roh_11', 'tta': True}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8f5ed3077bad45e4b1c18533e0f43b34",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/642 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'model_name': 'Unet', 'backbone': 'efficientnet-b7', 'img_size': [256, 256], 'num_classes': 1, 'model_pth': '/home/rohits/pv1/Contrail_Detection/output/exp_01_pl_s2/Unet/efficientnet-b7-256/checkpoint_dice_fold3.pth', 'threshold': 0.24, 'call_sign': 'roh_11', 'tta': True}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ddec686459704fcdadf9b0f5d4143dda",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/642 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "final_preds = []\n",
    "\n",
    "for idx, cfg in enumerate(CFGS):    \n",
    "    print(cfg)\n",
    "    val_transform = get_transform(cfg['img_size'])\n",
    "    valid_dataset = ContrailDataset(val_df, transform=val_transform)  \n",
    "\n",
    "    valid_loader = DataLoader(\n",
    "        valid_dataset, \n",
    "        batch_size = 32, #32, \n",
    "        shuffle = False, \n",
    "        num_workers = 2, \n",
    "        pin_memory = True, \n",
    "        drop_last = False\n",
    "    )\n",
    "\n",
    "    \n",
    "    if ensemple_type == \"mine\":\n",
    "        model = Net(cfg)    \n",
    "        model = torch.nn.DataParallel(model).cuda()\n",
    "        model.load_state_dict(torch.load(cfg['model_pth'], map_location=torch.device('cpu'))['model'])\n",
    "    else:\n",
    "        if idx <= 1:\n",
    "            model = load_model_timmunetplus(cfg['model_pth'], cfg['backbone'], cfg)\n",
    "        elif idx == 2:\n",
    "            model = load_model(cfg['model_pth'], cfg['backbone'])\n",
    "        elif idx == 3:\n",
    "            model = load_model3(cfg)\n",
    "        else:\n",
    "            model = Net(cfg)    \n",
    "            model = torch.nn.DataParallel(model).cuda()\n",
    "            model.load_state_dict(torch.load(cfg['model_pth'], map_location=torch.device('cpu'))['model'])\n",
    "\n",
    "    if cfg['tta']:\n",
    "        if ensemple_type == \"mine\":\n",
    "            model = tta.SegmentationTTAWrapper(model, tta.aliases.flip_transform(), merge_mode='mean')\n",
    "        else:\n",
    "            if idx <= 3:\n",
    "                model = tta.SegmentationTTAWrapper(model, tta.aliases.hflip_transform(), merge_mode='mean')\n",
    "            else:\n",
    "                model = tta.SegmentationTTAWrapper(model, tta.aliases.flip_transform(), merge_mode='mean')\n",
    "\n",
    "    \n",
    "    \n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "    \n",
    "    preds = []\n",
    "    \n",
    "    for index, (images) in enumerate(tqdm(valid_loader)):  \n",
    "        images  = images.to(device, dtype=torch.float)\n",
    "\n",
    "        with torch.inference_mode():\n",
    "            images = torch.nn.functional.interpolate(images,size=cfg['img_size'][0], mode='nearest')\n",
    "            pred = model(images)                     \n",
    "            pred = torch.nn.functional.interpolate(pred.sigmoid(), size=256, mode='nearest') \n",
    "            preds.append(torch.squeeze(pred, dim=1))\n",
    "\n",
    "            \n",
    "    model_preds = torch.cat(preds, dim=0).detach().cpu()  \n",
    "#     model_preds = torch.flatten(model_preds, start_dim=0, end_dim=1)  \n",
    "        \n",
    "    final_preds.append(model_preds)\n",
    "    \n",
    "    del model, model_preds\n",
    "    torch.cuda.empty_cache()\n",
    "    gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0c8d0160",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_preds = weighted_ensemble(params, final_preds)\n",
    "threshold = 0.59\n",
    "final_preds = (final_preds>threshold).double()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d6ec1cd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ids = val_df['id'].values\n",
    "# for (val, label_id) in tqdm(zip(final_preds, ids), total=len(ids)): \n",
    "#     mask = val.view(256, 256, 1).detach().cpu().numpy()\n",
    "#     np.save(f\"../../input/pseudo/{folder}_data_{NTB}/{label_id}/label_684cv_687lb.npy\", mask.astype('float16')) \n",
    "\n",
    "\n",
    "val_df['id'] = val_df['image'].apply(lambda x: x.split(\"/\")[-2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0a81fc41",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "272fa74d4a5a45668c3296c71fa76cb0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20529 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ids = val_df['id'].values\n",
    "for (val, label_id) in tqdm(zip(final_preds, ids), total=len(ids)): \n",
    "    mask = val.view(256, 256, 1).detach().cpu().numpy()\n",
    "    np.save(f\"../../input/pseudo/{folder}_data_{NTB}/{label_id}/label_684cv_687lb.npy\", mask.astype('float16')) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "98323071",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([256, 256])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_preds[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "44a1bdfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# val_df['image'][0].split(\"/\")[-2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "376b8552",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20529"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e52cb92",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e0ab014",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "679b89b9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
