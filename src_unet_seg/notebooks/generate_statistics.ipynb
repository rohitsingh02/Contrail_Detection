{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "77e5af39",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import ttach as tta\n",
    "import os\n",
    "import shutil\n",
    "import pathlib\n",
    "import gc\n",
    "from pathlib import Path\n",
    "from PIL import Image\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import cv2 as cv\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "# from tqdm.auto import tqdm\n",
    "from tqdm.notebook import tqdm\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch import optim\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "from torch.utils.data import Dataset\n",
    "import torchvision\n",
    "from torchvision import datasets\n",
    "import cv2\n",
    "from torch.cuda import amp\n",
    "\n",
    "import torchvision.transforms as T\n",
    "from torchvision.transforms import Compose, ToTensor, Resize\n",
    "from torchvision.utils import make_grid\n",
    "import optuna\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "import segmentation_models_pytorch as smp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "157ff8d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def seed_everything(seed=42):\n",
    "    '''Sets the seed of the entire notebook so results are the same every time we run.\n",
    "    This is for REPRODUCIBILITY.'''\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "12e6bf9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed_everything(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "c5654e79",
   "metadata": {},
   "outputs": [],
   "source": [
    "CFGS = [           \n",
    "#     {\n",
    "#         'model_name': 'Unet',\n",
    "#         'backbone': 'efficientnet-b7',\n",
    "#         'img_size': [256, 256],\n",
    "#         'num_classes': 1,\n",
    "#         'model_pth': '../../output/exp_pl2_new01/Unet/efficientnet-b7-256/checkpoint_dice.pth',\n",
    "#         'threshold': 0.84,\n",
    "#         'tta': True, \n",
    "#     },\n",
    "    {\n",
    "        'model_name': 'Unet',\n",
    "        'backbone': 'efficientnet-b7',\n",
    "        'img_size': [256, 256],\n",
    "        'num_classes': 1,\n",
    "        'model_pth': '/home/rohits/pv1/contrail/output/exp_s1_pl_03/pl_round2/efficientnet-b7-256-s2-2/checkpoint_dice.pth',\n",
    "        'threshold': 0.9,\n",
    "        'tta': True, \n",
    "    },\n",
    "    \n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "2ddaafa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "d58a5058",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ContrailDataset:\n",
    "    def __init__(self, df, transform=None):\n",
    "        self.df = df  \n",
    "        self.images = df['image']\n",
    "        self.labels = df['label']\n",
    "        self.transform =transform        \n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "        \n",
    "    def __getitem__(self, idx):\n",
    "        image = np.load(\"../../input/\" + self.images[idx]).astype(float)   \n",
    "        label = np.load(\"../../input/\" + self.labels[idx]).astype(float)\n",
    "        \n",
    "        \n",
    "        if self.transform :\n",
    "            data = self.transform(image=image, mask=label)\n",
    "            image  = data['image']\n",
    "            label  = data['mask']\n",
    "            image = np.transpose(image, (2, 0, 1))\n",
    "            label = np.transpose(label, (2, 0, 1))  \n",
    "            \n",
    "        class_label = 1 if label.sum() > 0 else 0\n",
    "            \n",
    "        return torch.tensor(image), torch.tensor(label), torch.tensor(class_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "985b3de5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self, cfg):\n",
    "        super().__init__()\n",
    "        self.cfg = cfg\n",
    "        \n",
    "        self.model = smp.Unet(\n",
    "            encoder_name=cfg[\"backbone\"],      # choose encoder, e.g. mobilenet_v2 or efficientnet-b7\n",
    "            encoder_weights=None,     # use `imagenet` pre-trained weights for encoder initialization\n",
    "            in_channels=3,                  # model input channels (1 for gray-scale images, 3 for RGB, etc.)\n",
    "            classes=cfg[\"num_classes\"],        # model output channels (number of classes in your dataset)\n",
    "            activation=None\n",
    "        )\n",
    "        \n",
    "    \n",
    "    def forward(self, inputs):\n",
    "        mask = self.model(inputs)\n",
    "        return mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b13dbb4e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "07bfce0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dice_coef(y_true, y_pred, thr=0.5, epsilon=1e-6):\n",
    "    y_true = y_true.to(torch.float32)\n",
    "    y_pred = (y_pred>thr).to(torch.float32)\n",
    "    inter = (y_true*y_pred).sum()\n",
    "    den = y_true.sum() + y_pred.sum()\n",
    "    dice = ((2*inter+epsilon)/(den+epsilon)).mean()\n",
    "    \n",
    "    return dice\n",
    "\n",
    "\n",
    "def iou_coef(y_true, y_pred, thr=0.5, epsilon=1e-6):\n",
    "    y_true = y_true.to(torch.float32)\n",
    "    y_pred = (y_pred>thr).to(torch.float32)\n",
    "    inter = (y_true*y_pred).sum()\n",
    "    union = (y_true + y_pred - y_true*y_pred).sum()\n",
    "    iou = ((inter+epsilon)/(union+epsilon)).mean(0)\n",
    "    return iou\n",
    "\n",
    "\n",
    "def get_transform(img_size):\n",
    "    transform = A.Compose([\n",
    "        A.Resize(*img_size, interpolation=cv2.INTER_NEAREST),\n",
    "    ], p=1.0)\n",
    "    return transform\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "9bc47b4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_preds(model, data_loader, img_size):\n",
    "    \n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "    \n",
    "    preds = []\n",
    "    masks = []\n",
    "    class_labels = []\n",
    "\n",
    "    for index, (image, mask, class_label) in enumerate(tqdm(data_loader)):  \n",
    "        image  = image.to(device, dtype=torch.float)\n",
    "        mask  = mask.to(device, dtype=torch.float)\n",
    "        class_label  = class_label.to(device, dtype=torch.int64)\n",
    "        class_labels.append(class_label)\n",
    "        \n",
    "        if img_size != 256:\n",
    "            mask = torch.nn.functional.interpolate(mask, size=256, mode='nearest')             \n",
    "        masks.append(torch.squeeze(mask, dim=1))\n",
    "\n",
    "        with torch.inference_mode():            \n",
    "            pred = model(image)                \n",
    "            pred = pred.sigmoid()\n",
    "\n",
    "            if img_size != 256:\n",
    "                pred = torch.nn.functional.interpolate(pred, size=256, mode='nearest') \n",
    "            preds.append(torch.squeeze(pred, dim=1))\n",
    "\n",
    "    \n",
    "    model_masks = torch.cat(masks, dim=0)\n",
    "    model_preds = torch.cat(preds, dim=0)\n",
    "    class_labels = torch.cat(class_labels, dim=0) \n",
    "    \n",
    "    \n",
    "    model_masks = torch.flatten(model_masks, start_dim=0, end_dim=1)\n",
    "    model_preds = torch.flatten(model_preds, start_dim=0, end_dim=1)  \n",
    "    class_labels = torch.flatten(class_labels)  \n",
    "    \n",
    "    best_threshold = 0.0\n",
    "    best_dice_score = 0.0\n",
    "    for threshold in [i / 100 for i in range(101)] :\n",
    "        score = dice_coef(model_masks, model_preds, thr=threshold).cpu().detach().numpy() \n",
    "        if score > best_dice_score:\n",
    "            best_dice_score = score\n",
    "            best_threshold = threshold\n",
    "            \n",
    "            \n",
    "    return model_masks, model_preds, best_dice_score, best_threshold, class_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "61492c7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_stats(mask, pred, th, stats, append = \"\"):\n",
    "    aucpr = iou_coef(mask, pred, thr=th, epsilon=1e-6)\n",
    "    tp, fp, fn, tn = smp.metrics.get_stats(pred, mask.round().long(), mode='binary', threshold=th)\n",
    "    iou_image = smp.metrics.iou_score(tp, fp, fn, tn, reduction=\"micro-imagewise\")\n",
    "    iou_overall = smp.metrics.iou_score(tp, fp, fn, tn, reduction=\"macro\")\n",
    "\n",
    "    stats += f\"Global Dice Score {append}: {score}, TH: {th} | IOU_IMAGE_WISE: {iou_image},  IOU_OVERALL: {iou_overall}\\n\"\n",
    "    return stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "8629a5ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# val_df.shape, val_df_0.shape, val_df_1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "646ce6cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "val_df = pd.read_csv(\"../../input/val_df_filled.csv\")\n",
    "val_df_0 = val_df.loc[val_df['class'] == 0].reset_index(drop=True)\n",
    "val_df_1 = val_df.loc[val_df['class'] == 1].reset_index(drop=True)\n",
    "\n",
    "\n",
    "val_transform = get_transform([256, 256])\n",
    "valid_dataset = ContrailDataset(val_df, transform=val_transform)  \n",
    "valid_dataset0 = ContrailDataset(val_df_0, transform=val_transform)  \n",
    "valid_dataset1 = ContrailDataset(val_df_1, transform=val_transform)  \n",
    "\n",
    "\n",
    "valid_loader = DataLoader(\n",
    "    valid_dataset, \n",
    "    batch_size = 32, #32, \n",
    "    shuffle = False, \n",
    "    num_workers = 2, \n",
    "    pin_memory = True, \n",
    "    drop_last = False\n",
    ")\n",
    "\n",
    "valid_loader0 = DataLoader(\n",
    "    valid_dataset0, \n",
    "    batch_size = 32, #32, \n",
    "    shuffle = False, \n",
    "    num_workers = 2, \n",
    "    pin_memory = True, \n",
    "    drop_last = False\n",
    ")\n",
    "\n",
    "valid_loader1 = DataLoader(\n",
    "    valid_dataset1, \n",
    "    batch_size = 32, #32, \n",
    "    shuffle = False, \n",
    "    num_workers = 2, \n",
    "    pin_memory = True, \n",
    "    drop_last = False\n",
    ")\n",
    "\n",
    "\n",
    "cfg = CFGS[0]\n",
    "\n",
    "model = Net(cfg)\n",
    "model = torch.nn.DataParallel(model).cuda()\n",
    "model.load_state_dict(torch.load(cfg['model_pth'], map_location=torch.device('cpu'))['model'])\n",
    "model_tta = tta.SegmentationTTAWrapper(model, tta.aliases.flip_transform(), merge_mode='mean')     \n",
    "print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "e1d72a60",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c1c439a00a1a424caf61c6b5227d483e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/58 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "34160299b71541339703ef3247c8c77c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/18 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a563f292372942eeb2cbb4bc7ec5c5b8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/58 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d63c767a6cb0429ca99cfc4e66c4d4d9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/18 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "stats = \"\"\n",
    "mask, pred, score, th, cls_labels = get_preds(model, valid_loader, img_size=256)\n",
    "stats = generate_stats(mask, pred, th, stats, append = \"TTA:0\")\n",
    "\n",
    "mask, pred, score, th, cls_labels = get_preds(model, valid_loader1, img_size=256)\n",
    "stats = generate_stats(mask, pred, th, stats, append = \"POS TTA:0\")\n",
    "\n",
    "mask, pred, score, th, cls_labels = get_preds(model_tta, valid_loader, img_size=256)\n",
    "stats = generate_stats(mask, pred, th, stats, append = \"TTA:3\")\n",
    "\n",
    "mask, pred, score, th, cls_labels = get_preds(model_tta, valid_loader1, img_size=256)\n",
    "stats = generate_stats(mask, pred, th, stats, append = \"POS TTA:3\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91f7d4a6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "c9ad25f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "****************************************************************************************************\n",
      "Global Dice Score TTA:0: 0.6755469441413879, TH: 0.75 | IOU_IMAGE_WISE: 0.9531981348991394,  IOU_OVERALL: 0.5080936551094055\n",
      "Global Dice Score POS TTA:0: 0.6846645474433899, TH: 0.74 | IOU_IMAGE_WISE: 0.8537121415138245,  IOU_OVERALL: 0.5184818506240845\n",
      "Global Dice Score TTA:3: 0.6779290437698364, TH: 0.66 | IOU_IMAGE_WISE: 0.9536939263343811,  IOU_OVERALL: 0.5107443928718567\n",
      "Global Dice Score POS TTA:3: 0.6869837045669556, TH: 0.47 | IOU_IMAGE_WISE: 0.8542597889900208,  IOU_OVERALL: 0.5211914777755737\n",
      "\n",
      "****************************************************************************************************\n"
     ]
    }
   ],
   "source": [
    "print(\"*\"*100)\n",
    "print(stats)\n",
    "print(\"*\"*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bbd34c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Global Dice Score TTA:0: 0.6759867668151855, TH: 0.9 | IOU_IMAGE_WISE: 0.9537177681922913,  IOU_OVERALL: 0.5087465047836304\n",
    "# Global Dice Score TTA:0: 0.6844078302383423, TH: 0.58 | IOU_IMAGE_WISE: 0.8528633117675781,  IOU_OVERALL: 0.5184430480003357\n",
    "# Global Dice Score TTA:0: 0.6778432130813599, TH: 0.57 | IOU_IMAGE_WISE: 0.9537582993507385,  IOU_OVERALL: 0.5108285546302795\n",
    "# Global Dice Score TTA:0: 0.6860638856887817, TH: 0.28 | IOU_IMAGE_WISE: 0.8528570532798767,  IOU_OVERALL: 0.5203468799591064"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "666ef0b2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9345648b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "2f9a65b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1856, 256, 256])"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "ddc01374",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1856, 256, 256])"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "c3c8fc8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "tp, fp, fn, tn = smp.metrics.get_stats(pred, mask.round().long(), mode='binary', threshold=th)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "eaf4b11e",
   "metadata": {},
   "outputs": [],
   "source": [
    "recall_image = smp.metrics.recall(tp, fp, fn, tn, reduction=\"micro-imagewise\")\n",
    "precision_image = smp.metrics.precision(tp, fp, fn, tn, reduction=\"micro-imagewise\")\n",
    "iou_score_image = smp.metrics.iou_score(tp, fp, fn, tn, reduction=\"micro-imagewise\")\n",
    "\n",
    "\n",
    "recall_overall = smp.metrics.recall(tp, fp, fn, tn, reduction=\"macro\")\n",
    "precision_overall = smp.metrics.precision(tp, fp, fn, tn, reduction=\"macro\")\n",
    "iou_score_overall = smp.metrics.iou_score(tp, fp, fn, tn, reduction=\"macro\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "ebe1c614",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(0.8831, device='cuda:0'),\n",
       " tensor(0.6825, device='cuda:0'),\n",
       " tensor(0.8766, device='cuda:0'),\n",
       " tensor(0.6682, device='cuda:0'),\n",
       " tensor(0.7898, device='cuda:0'),\n",
       " tensor(0.5092, device='cuda:0'))"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precision, precision_overall, recall, recall_overall , iou_score, iou_score_overall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3129e998",
   "metadata": {},
   "outputs": [],
   "source": [
    "(tensor(0.8831, device='cuda:0'),\n",
    " tensor(0.6670, device='cuda:0'),\n",
    " tensor(0.8766, device='cuda:0'),\n",
    " tensor(0.6833, device='cuda:0'),\n",
    " tensor(0.7898, device='cuda:0'),\n",
    " tensor(0.5090, device='cuda:0'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "a0399669",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.8307, device='cuda:0')"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "smp.metrics.false_positive_rate(tp, fp, fn, tn, reduction=\"micro-imagewise\")\n",
    "smp.metrics.false_negative_rate(tp, fp, fn, tn, reduction=\"micro-imagewise\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "8c8890ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1856, 256, 256])"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "42fab176",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([58, 32])"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cls_labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "f963a668",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1856])"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.flatten(cls_labels).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "d63d407c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1856, 256])"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "ee500421",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image</th>\n",
       "      <th>label</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>valid_data/3687499407028137410/image.npy</td>\n",
       "      <td>valid_data/3687499407028137410/label.npy</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>valid_data/7355354609194882312/image.npy</td>\n",
       "      <td>valid_data/7355354609194882312/label.npy</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>valid_data/7547747455642200110/image.npy</td>\n",
       "      <td>valid_data/7547747455642200110/label.npy</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>valid_data/8604370548989406919/image.npy</td>\n",
       "      <td>valid_data/8604370548989406919/label.npy</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>valid_data/4746167155668084215/image.npy</td>\n",
       "      <td>valid_data/4746167155668084215/label.npy</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1299</th>\n",
       "      <td>valid_data/7206666542994541713/image.npy</td>\n",
       "      <td>valid_data/7206666542994541713/label.npy</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1300</th>\n",
       "      <td>valid_data/2819090710836460710/image.npy</td>\n",
       "      <td>valid_data/2819090710836460710/label.npy</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1301</th>\n",
       "      <td>valid_data/922629314296188212/image.npy</td>\n",
       "      <td>valid_data/922629314296188212/label.npy</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1302</th>\n",
       "      <td>valid_data/3319793057592206418/image.npy</td>\n",
       "      <td>valid_data/3319793057592206418/label.npy</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1303</th>\n",
       "      <td>valid_data/8195127976521848310/image.npy</td>\n",
       "      <td>valid_data/8195127976521848310/label.npy</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1304 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         image  \\\n",
       "0     valid_data/3687499407028137410/image.npy   \n",
       "1     valid_data/7355354609194882312/image.npy   \n",
       "2     valid_data/7547747455642200110/image.npy   \n",
       "3     valid_data/8604370548989406919/image.npy   \n",
       "4     valid_data/4746167155668084215/image.npy   \n",
       "...                                        ...   \n",
       "1299  valid_data/7206666542994541713/image.npy   \n",
       "1300  valid_data/2819090710836460710/image.npy   \n",
       "1301   valid_data/922629314296188212/image.npy   \n",
       "1302  valid_data/3319793057592206418/image.npy   \n",
       "1303  valid_data/8195127976521848310/image.npy   \n",
       "\n",
       "                                         label  class  \n",
       "0     valid_data/3687499407028137410/label.npy      0  \n",
       "1     valid_data/7355354609194882312/label.npy      0  \n",
       "2     valid_data/7547747455642200110/label.npy      0  \n",
       "3     valid_data/8604370548989406919/label.npy      0  \n",
       "4     valid_data/4746167155668084215/label.npy      0  \n",
       "...                                        ...    ...  \n",
       "1299  valid_data/7206666542994541713/label.npy      0  \n",
       "1300  valid_data/2819090710836460710/label.npy      0  \n",
       "1301   valid_data/922629314296188212/label.npy      0  \n",
       "1302  valid_data/3319793057592206418/label.npy      0  \n",
       "1303  valid_data/8195127976521848310/label.npy      0  \n",
       "\n",
       "[1304 rows x 3 columns]"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_df_0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2e41154",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "042ebc4e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
