{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "041ac14f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# os.environ['CUDA_VISIBLE_DEVICES'] = '1'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "77e5af39",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import pathlib\n",
    "import gc\n",
    "import pandas as pd\n",
    "import ttach as tta\n",
    "from pathlib import Path\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import cv2 as cv\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "# from tqdm.auto import tqdm\n",
    "from tqdm.notebook import tqdm\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch import optim\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "import torchvision\n",
    "from torchvision import datasets\n",
    "import cv2\n",
    "from torch.cuda import amp\n",
    "\n",
    "import torchvision.transforms as T\n",
    "from torchvision.transforms import Compose, ToTensor, Resize\n",
    "from torchvision.utils import make_grid\n",
    "import optuna\n",
    "\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "import segmentation_models_pytorch as smp\n",
    "import timm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "157ff8d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def seed_everything(seed=42):\n",
    "    '''Sets the seed of the entire notebook so results are the same every time we run.\n",
    "    This is for REPRODUCIBILITY.'''\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "12e6bf9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed_everything(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddb77d81",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c5654e79",
   "metadata": {},
   "outputs": [],
   "source": [
    "CFGS = [ \n",
    "    \n",
    "#     {\n",
    "#         'model_name': 'Unet++',\n",
    "#         'backbone': 'tf_efficientnet_b7_ns',\n",
    "#         'img_size': [512, 512],\n",
    "#         'num_classes': 1,\n",
    "#         'model_pth':  '../../output/nirjhar/qishentrialv2fpn512_tf_efficientnet_b7_ns_best_epochcv650lb675-00.bin',\n",
    "#         'threshold': 0.62, #0.24,\n",
    "#         'call_sign': \"nir_01\",\n",
    "#         'tta': True\n",
    "#     },\n",
    "\n",
    "#     {\n",
    "#         'model_name': 'Unet++',\n",
    "#         'backbone': 'tf_efficientnet_b7_ns',\n",
    "#         'img_size': [512, 512],\n",
    "#         'num_classes': 1,\n",
    "#         'model_pth':  '../../output/nirjhar/qishentrialv512unetplus_tf_efficientnet_b7_ns_best_epochstage2cv669-00.bin',\n",
    "#         'threshold': 0.62, #0.24,\n",
    "#         'call_sign': \"nir_02\", \n",
    "#         'tta': True\n",
    "#     },\n",
    "    \n",
    "#     {\n",
    "#         'model_name': 'Unet',\n",
    "#         'backbone': 'eca_nfnet_l1',\n",
    "#         'img_size': [512, 512],\n",
    "#         'num_classes': 1,\n",
    "#         'model_pth':  '../../output/nirjhar/unetplusecarnf01_eca_nfnet_l1_best_epochstage2cv656-00.bin',\n",
    "#         'threshold': 0.62, #0.24,\n",
    "#         'call_sign': \"nir_03\",\n",
    "#         'tta': True\n",
    "#     },\n",
    "#     {\n",
    "#         'model_name': 'Unet',\n",
    "#         'backbone': 'efficientnet-b7',\n",
    "#         'img_size': [256, 256],\n",
    "#         'num_classes': 1,\n",
    "#         'model_pth':  '../../output/exp_s1_pl_03/pl_round1/efficientnet-b7-256-s2/checkpoint_dice.pth',\n",
    "#         'threshold': 0.24, #0.24,\n",
    "#         'call_sign': \"roh_01\",\n",
    "#         'tta': True\n",
    "#     },   \n",
    "    \n",
    "#     {\n",
    "#         'model_name': 'Unet',\n",
    "#         'backbone': 'efficientnet-b7',\n",
    "#         'img_size': [256, 256],\n",
    "#         'num_classes': 1,\n",
    "#         'model_pth':  '/home/rohits/pv1/contrail/output/exp_s1_pl_03/pl_round2/efficientnet-b7-256-s2/checkpoint_dice.pth',\n",
    "#         'threshold': 0.62, #0.24,\n",
    "#         'call_sign': \"roh_02\",\n",
    "#         'tta': True\n",
    "#     }, \n",
    "#     {\n",
    "#         'model_name': 'Unet',\n",
    "#         'backbone': 'efficientnet-b7',\n",
    "#         'img_size': [256, 256],\n",
    "#         'num_classes': 1,\n",
    "#         'model_pth':  '../../output/exp_pre/Unet/efficientnet-b7-256-s2/checkpoint_dice.pth',\n",
    "#         'threshold': 0.24, #0.24,\n",
    "#         'call_sign': \"roh_03\", \n",
    "#         'tta': True\n",
    "#     },   \n",
    "#     {\n",
    "#         'model_name': 'Unet',\n",
    "#         'backbone': 'efficientnet-b7',\n",
    "#         'img_size': [256, 256],\n",
    "#         'num_classes': 1,\n",
    "#         'model_pth':  '../../output/exp_pre/Unet/efficientnet-b7-256-s3/checkpoint_dice.pth',\n",
    "#         'threshold': 0.24, #0.24,\n",
    "#         'call_sign': \"roh_04\", \n",
    "#         'tta': True\n",
    "#     },   \n",
    "    \n",
    "    \n",
    "#     {\n",
    "#         'model_name': 'Unet',\n",
    "#         'backbone': 'timm-resnest26d',\n",
    "#         'img_size': [256, 256],\n",
    "#         'num_classes': 1,\n",
    "#         'model_pth':  '../../output/exp_pre/Unet/timm-resnest26d-256/checkpoint_dice.pth',\n",
    "#         'threshold': 0.39, #0.24,\n",
    "#         'call_sign': \"roh_05\", \n",
    "#         'tta': True\n",
    "#     }, \n",
    "    \n",
    "#     {\n",
    "#         'model_name': 'Unet',\n",
    "#         'backbone': 'timm-resnest26d',\n",
    "#         'img_size': [256, 256],\n",
    "#         'num_classes': 1,\n",
    "#         'model_pth':  '../../output/exp_pre/Unet/timm-resnest26d-256-s2/checkpoint_dice.pth',\n",
    "#         'threshold': 0.39, #0.24,\n",
    "#         'call_sign': \"roh_06\", \n",
    "#         'tta': True\n",
    "#     }, \n",
    "    \n",
    "#     {\n",
    "#         'model_name': 'Unet',\n",
    "#         'backbone': 'timm-resnest26d',\n",
    "#         'img_size': [256, 256],\n",
    "#         'num_classes': 1,\n",
    "#         'model_pth':  '../../output/exp_pre/Unet/timm-resnest26d-256-s3/checkpoint_dice.pth',\n",
    "#         'threshold': 0.39, #0.24,\n",
    "#         'call_sign': \"roh_07\", \n",
    "#         'tta': True\n",
    "#     }, \n",
    "    \n",
    "        \n",
    "    {\n",
    "        'model_name': 'Unet',\n",
    "        'backbone': 'efficientnet-b7',\n",
    "        'img_size': [256, 256],\n",
    "        'num_classes': 1,\n",
    "        'model_pth':  '/home/rohits/pv1/contrail/output/exp_02_s2/Unet/efficientnet-b7-256/checkpoint_dice_fold0.pth',\n",
    "        'threshold': 0.39, #0.24,\n",
    "        'call_sign': \"roh_1_00\", \n",
    "        'tta': True\n",
    "    }, \n",
    "    \n",
    "    \n",
    "    {\n",
    "        'model_name': 'Unet',\n",
    "        'backbone': 'efficientnet-b7',\n",
    "        'img_size': [256, 256],\n",
    "        'num_classes': 1,\n",
    "        'model_pth':  '/home/rohits/pv1/contrail/output/exp_02_s2/Unet/efficientnet-b7-256/checkpoint_dice_fold1.pth',\n",
    "        'threshold': 0.39, #0.24,\n",
    "        'call_sign': \"roh_1_01\", \n",
    "        'tta': True\n",
    "    }, \n",
    "    \n",
    "    \n",
    "        \n",
    "    {\n",
    "        'model_name': 'Unet',\n",
    "        'backbone': 'efficientnet-b7',\n",
    "        'img_size': [256, 256],\n",
    "        'num_classes': 1,\n",
    "        'model_pth':  '/home/rohits/pv1/contrail/output/exp_02_s2/Unet/efficientnet-b7-256/checkpoint_dice_fold2.pth',\n",
    "        'threshold': 0.39, #0.24,\n",
    "        'call_sign': \"roh_1_02\", \n",
    "        'tta': True\n",
    "    }, \n",
    "    \n",
    "    \n",
    "        \n",
    "#     {\n",
    "#         'model_name': 'Unet',\n",
    "#         'backbone': 'efficientnet-b7',\n",
    "#         'img_size': [256, 256],\n",
    "#         'num_classes': 1,\n",
    "#         'model_pth':  '/home/rohits/pv1/contrail/output/exp_02_s2/Unet/efficientnet-b7-256/checkpoint_dice_fold3.pth',\n",
    "#         'threshold': 0.39, #0.24,\n",
    "#         'call_sign': \"roh_1_03\", \n",
    "#         'tta': True\n",
    "#     }, \n",
    "    \n",
    "    \n",
    "        \n",
    "#     {\n",
    "#         'model_name': 'Unet',\n",
    "#         'backbone': 'efficientnet-b7',\n",
    "#         'img_size': [256, 256],\n",
    "#         'num_classes': 1,\n",
    "#         'model_pth':  '/home/rohits/pv1/contrail/output/exp_02_s2/Unet/efficientnet-b7-256/checkpoint_dice_fold4.pth',\n",
    "#         'threshold': 0.39, #0.24,\n",
    "#         'call_sign': \"roh_1_04\", \n",
    "#         'tta': True\n",
    "#     }, \n",
    "\n",
    "\n",
    "\n",
    "]\n",
    "\n",
    "ensemple_type = \"mine\" #\"No\" #\"mine\"\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2ddaafa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d58a5058",
   "metadata": {},
   "outputs": [],
   "source": [
    "# class Dataset:\n",
    "#     def __init__(self, df, transform=None):   \n",
    "#         self.images = df['image']\n",
    "#         self.labels = df['label']\n",
    "#         self.transform =transform\n",
    "        \n",
    "#     def __len__(self):\n",
    "#         return len(self.images)\n",
    "        \n",
    "#     def __getitem__(self, idx):\n",
    "#         image = np.load(self.images[idx]).astype(float)\n",
    "#         if  self.transform :\n",
    "#             data = self.transform(image=image)\n",
    "#             image  = data['image']\n",
    "#             image = np.transpose(image, (2, 0, 1))\n",
    "#         return torch.tensor(image)\n",
    "    \n",
    "    \n",
    "    \n",
    "class ContrailDataset:\n",
    "    def __init__(self, df, transform=None):\n",
    "        self.df = df  \n",
    "        self.images = df['image']\n",
    "        self.labels = df['label']\n",
    "        self.transform =transform\n",
    "        \n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "        \n",
    "    def __getitem__(self, idx):\n",
    "        image = np.load(\"../../input/\" + self.images[idx]).astype(float)   \n",
    "        label = np.load(\"../../input/\" + self.labels[idx]).astype(float)\n",
    "        \n",
    "        \n",
    "        # label_cls = 1 if label.sum() > 0 else 0\n",
    "        if self.transform :\n",
    "            data = self.transform(image=image, mask=label)\n",
    "            image  = data['image']\n",
    "            label  = data['mask']\n",
    "            image = np.transpose(image, (2, 0, 1))\n",
    "            label = np.transpose(label, (2, 0, 1))    \n",
    "            \n",
    "        return torch.tensor(image), torch.tensor(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "985b3de5",
   "metadata": {},
   "outputs": [],
   "source": [
    "###TImmunetplusplus model Nirjhar\n",
    "\n",
    "n_blocks = 4\n",
    "\n",
    "class TimmSegModel(nn.Module):\n",
    "    def __init__(self, backbone, cfg, segtype='unet', pretrained=True):\n",
    "        super(TimmSegModel, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 6, 3, stride=1, padding=1, bias=False)\n",
    "        self.conv2 = nn.Conv2d(6, 12, 3, stride=1, padding=1, bias=False)\n",
    "        self.conv3 = nn.Conv2d(12, 36, 3, stride=1, padding=1, bias=False)\n",
    "        self.mybn1 = nn.BatchNorm2d(6)\n",
    "        self.mybn2 = nn.BatchNorm2d(12)\n",
    "        self.mybn3 = nn.BatchNorm2d(36)     \n",
    "        self.encoder = timm.create_model(\n",
    "            backbone,\n",
    "            in_chans=3,\n",
    "            features_only=True,\n",
    "            drop_rate=0.8,\n",
    "            drop_path_rate=0.5,\n",
    "            pretrained=False\n",
    "        )\n",
    "        self.encoder.conv_stem=nn.Conv2d(6, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
    "\n",
    "        self.encoder.blocks[5] = nn.Identity()\n",
    "        self.encoder.blocks[6] = nn.Sequential(\n",
    "            nn.Conv2d(self.encoder.blocks[4][2].conv_pwl.out_channels, 320, 1),\n",
    "            nn.BatchNorm2d(320),\n",
    "            nn.ReLU6(),\n",
    "        )\n",
    "        tr = torch.randn(1,6,64,64)\n",
    "        g = self.encoder(tr)\n",
    "        encoder_channels = [1] + [_.shape[1] for _ in g]\n",
    "        decoder_channels = [256, 128, 64, 32, 16]\n",
    "        if segtype == 'unet':\n",
    "            self.decoder = smp.decoders.unetplusplus.decoder.UnetPlusPlusDecoder(\n",
    "                encoder_channels=encoder_channels[:n_blocks+1],\n",
    "                decoder_channels=decoder_channels[:n_blocks],\n",
    "                n_blocks=n_blocks,\n",
    "            )\n",
    "\n",
    "        self.segmentation_head = nn.Conv2d(\n",
    "            decoder_channels[n_blocks-1],\n",
    "            cfg[\"num_classes\"], \n",
    "            kernel_size=(3, 3),\n",
    "            stride=(1, 1), \n",
    "            padding=(1, 1)\n",
    "        )\n",
    "\n",
    "    def forward(self,x):\n",
    "        x = F.relu6(self.mybn1(self.conv1(x)))\n",
    "        global_features = [0] + self.encoder(x)[:n_blocks]\n",
    "        seg_features = self.decoder(*global_features)\n",
    "        seg_features = self.segmentation_head(seg_features)\n",
    "        return seg_features\n",
    "    \n",
    "\n",
    "#path='./exp/baselinev2/qishentrialv2_tf_efficientnet_b7_ns_last_epoch-00.bin'\n",
    "\n",
    "def build_model_timmunetplus(backbone, cfg):\n",
    "    model = TimmSegModel(backbone, cfg)\n",
    "    return model\n",
    "\n",
    "def load_model_timmunetplus(path, backbone, cfg):\n",
    "    model = build_model_timmunetplus(backbone, cfg)\n",
    "    model.load_state_dict(torch.load(path))\n",
    "    return model\n",
    "\n",
    "\n",
    "#### Model 2 Nirjhar\n",
    "\n",
    "n_blocks =4\n",
    "class TimmSegModel2(nn.Module):\n",
    "    def __init__(self, backbone, segtype='unet', pretrained=True):\n",
    "        super(TimmSegModel2, self).__init__()\n",
    "\n",
    "        self.encoder = timm.create_model(\n",
    "            backbone,\n",
    "            in_chans=3,\n",
    "            features_only=True,\n",
    "            drop_rate=0.5,\n",
    "            pretrained=False\n",
    "        )\n",
    "        g = self.encoder(torch.rand(1, 3, 128, 128))\n",
    "        encoder_channels = [1] + [_.shape[1] for _ in g]\n",
    "        decoder_channels = [256, 128, 64, 32, 16]\n",
    "        if segtype == 'unet':\n",
    "            self.decoder = smp.decoders.unetplusplus.decoder.UnetPlusPlusDecoder(\n",
    "                encoder_channels=encoder_channels[:n_blocks+1],\n",
    "                decoder_channels=decoder_channels[:n_blocks],\n",
    "                n_blocks=n_blocks,\n",
    "            )\n",
    "\n",
    "        self.segmentation_head = nn.Sequential(\n",
    "            nn.Conv2d(decoder_channels[n_blocks-1], 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)),\n",
    "            nn.UpsamplingBilinear2d(scale_factor=1))\n",
    "\n",
    "    def forward(self,x):\n",
    "        global_features = [0] + self.encoder(x)[:n_blocks]\n",
    "        seg_features = self.decoder(*global_features)\n",
    "        seg_features = self.segmentation_head(seg_features)\n",
    "        return seg_features\n",
    "    \n",
    "#path='./exp/baselinev2/qishentrialv2_tf_efficientnet_b7_ns_last_epoch-00.bin'\n",
    "\n",
    "\n",
    "def build_model(backbone):\n",
    "    model = TimmSegModel2(backbone, segtype='unet')\n",
    "    return model\n",
    "\n",
    "def load_model(path,backbone):\n",
    "    model = build_model(backbone)\n",
    "    model.load_state_dict(torch.load(path))\n",
    "    return model\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "## Rohit Model \n",
    "class Net(nn.Module):\n",
    "    def __init__(self, cfg):\n",
    "        super().__init__()\n",
    "        self.cfg = cfg\n",
    "        \n",
    "        self.model = smp.Unet(\n",
    "            encoder_name=cfg[\"backbone\"],     \n",
    "            encoder_weights=None,   \n",
    "            in_channels=3,  \n",
    "            classes=cfg[\"num_classes\"],\n",
    "            activation=None\n",
    "        )\n",
    "        \n",
    "    \n",
    "    def forward(self, inputs):\n",
    "        mask = self.model(inputs)\n",
    "        return mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "07bfce0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dice_coef(y_true, y_pred, thr=0.5, epsilon=1e-6):\n",
    "    y_true = y_true.to(torch.float32)\n",
    "    y_pred = (y_pred>thr).to(torch.float32)\n",
    "    inter = (y_true*y_pred).sum()\n",
    "    den = y_true.sum() + y_pred.sum()\n",
    "    dice = ((2*inter+epsilon)/(den+epsilon)).mean()\n",
    "    \n",
    "    return dice\n",
    "\n",
    "\n",
    "def get_transform(img_size):\n",
    "    transform = A.Compose([\n",
    "        A.Resize(*img_size, interpolation=cv2.INTER_NEAREST),\n",
    "    ], p=1.0)\n",
    "    return transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "01378f87",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_df =pd.read_csv(\"../../input/val_df_filled.csv\")\n",
    "train_df =pd.read_csv(\"../../input/train_folds.csv\")\n",
    "\n",
    "# val_df = val_df.loc[val_df['class'] == 1].reset_index(drop=True)\n",
    "# val_df = val_df.loc[val_df['class'] == 0].reset_index(drop=True)\n",
    "\n",
    "final_preds = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "646ce6cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# for idx, cfg in enumerate(CFGS):\n",
    "# #     if idx <= 6:\n",
    "# #         continue\n",
    "    \n",
    "# #     val_df = pd.read_csv(\"../../input/val_df_filled.csv\")\n",
    "#     val_df = train_df.loc[train_df.fold == idx]\n",
    "    \n",
    "    \n",
    "#     print(cfg)\n",
    "#     val_transform = get_transform(cfg['img_size'])\n",
    "#     valid_dataset = ContrailDataset(val_df, transform=val_transform)  \n",
    "\n",
    "#     valid_loader = DataLoader(\n",
    "#         valid_dataset, \n",
    "#         batch_size = 32, #32, \n",
    "#         shuffle = False, \n",
    "#         num_workers = 2, \n",
    "#         pin_memory = True, \n",
    "#         drop_last = False\n",
    "#     )\n",
    "\n",
    "    \n",
    "\n",
    "#     if ensemple_type == \"mine\":\n",
    "#         model = Net(cfg)    \n",
    "#         model = torch.nn.DataParallel(model).cuda()\n",
    "#         model.load_state_dict(torch.load(cfg['model_pth'], map_location=torch.device('cpu'))['model'])\n",
    "#     else:\n",
    "#         if idx <= 1:\n",
    "#             model = load_model_timmunetplus(cfg['model_pth'], cfg['backbone'], cfg)\n",
    "#         elif idx == 2:\n",
    "#             model = load_model(cfg['model_pth'], cfg['backbone'])\n",
    "\n",
    "#         else:\n",
    "#             model = Net(cfg)    \n",
    "#             model = torch.nn.DataParallel(model).cuda()\n",
    "#             model.load_state_dict(torch.load(cfg['model_pth'], map_location=torch.device('cpu'))['model'])\n",
    "\n",
    "#     if cfg['tta']:\n",
    "#         if ensemple_type == \"mine\":\n",
    "#             model = tta.SegmentationTTAWrapper(model, tta.aliases.flip_transform(), merge_mode='mean')\n",
    "#         else:\n",
    "#             if idx <= 2:\n",
    "#                 model = tta.SegmentationTTAWrapper(model, tta.aliases.hflip_transform(), merge_mode='mean')\n",
    "#             else:\n",
    "#                 model = tta.SegmentationTTAWrapper(model, tta.aliases.flip_transform(), merge_mode='mean')\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "#     model.to(device)\n",
    "#     model.eval()\n",
    "    \n",
    "#     preds = []\n",
    "#     masks_ = []\n",
    "    \n",
    "#     for index, (images, masks) in enumerate(tqdm(valid_loader)):  \n",
    "#         images  = images.to(device, dtype=torch.float)\n",
    "#         masks  = masks.to(device, dtype=torch.float)\n",
    "#         if cfg['img_size'][0] != 256:\n",
    "#             masks = torch.nn.functional.interpolate(masks, size=256, mode='nearest') \n",
    "            \n",
    "#         masks_.append(torch.squeeze(masks, dim=1))\n",
    "\n",
    "#         with torch.inference_mode():\n",
    "#             images = torch.nn.functional.interpolate(images,size=cfg['img_size'][0], mode='nearest')\n",
    "#             pred = model(images)                     \n",
    "#             pred = torch.nn.functional.interpolate(pred, size=256, mode='nearest') \n",
    "\n",
    "#             preds.append(torch.squeeze(pred, dim=1))\n",
    "\n",
    "            \n",
    "               \n",
    "            \n",
    "#     model_masks = torch.cat(masks_, dim=0)\n",
    "#     model_preds = torch.cat(preds, dim=0)\n",
    "    \n",
    "#     model_masks = torch.flatten(model_masks, start_dim=0, end_dim=1)\n",
    "#     model_preds = torch.flatten(model_preds, start_dim=0, end_dim=1)  \n",
    "    \n",
    "    \n",
    "# #     torch.save(model_preds, f\"../../output/final_preds/{cfg['call_sign']}.pt\")\n",
    "    \n",
    "    \n",
    "# #     if idx == 0:\n",
    "# #         torch.save(model_masks, f'../../output/final_preds/val_masks.pt')\n",
    "\n",
    "        \n",
    "        \n",
    "#     best_threshold = 0.0\n",
    "#     best_dice_score = 0.0\n",
    "#     for threshold in [i / 100 for i in range(101)] :\n",
    "#         score = dice_coef(model_masks, model_preds.sigmoid(), thr=threshold).cpu().detach().numpy() \n",
    "#         if score > best_dice_score:\n",
    "#             best_dice_score = score\n",
    "#             best_threshold = threshold\n",
    "    \n",
    "        \n",
    "#     print(best_dice_score, best_threshold)\n",
    "#     final_preds.append(model_preds)\n",
    "    \n",
    "#     del model\n",
    "#     torch.cuda.empty_cache()\n",
    "#     gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a9976bb3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "613c6720af744d9d8428899d2cc4a05b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/140 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f2eb09fff1074288a2674c23f52bc8dc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/140 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f2ca13a0c3934a269f63cf3cbe244fac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/140 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "final_masks = []\n",
    "final_preds = []\n",
    "\n",
    "for idx, cfg in enumerate(CFGS):\n",
    "    val_df = train_df.loc[train_df.fold == idx].reset_index(drop=True) \n",
    "#     val_df =pd.read_csv(\"../../input/val_df_filled.csv\")\n",
    "\n",
    "#     val_df = val_df.loc[val_df['class'] == 1]\n",
    "\n",
    "    \n",
    "    val_transform = get_transform(cfg['img_size'])\n",
    "    valid_dataset = ContrailDataset(val_df, transform=val_transform)  \n",
    "\n",
    "    valid_loader = DataLoader(\n",
    "        valid_dataset, \n",
    "        batch_size = 32, #32, \n",
    "        shuffle = False, \n",
    "        num_workers = 2, \n",
    "        pin_memory = True, \n",
    "        drop_last = False\n",
    "    )\n",
    "\n",
    "    \n",
    "\n",
    "    if ensemple_type == \"mine\":\n",
    "        model = Net(cfg)    \n",
    "        model = torch.nn.DataParallel(model).cuda()\n",
    "        model.load_state_dict(torch.load(cfg['model_pth'], map_location=torch.device('cpu'))['model'])\n",
    "    else:\n",
    "        if idx <= 1:\n",
    "            model = load_model_timmunetplus(cfg['model_pth'], cfg['backbone'], cfg)\n",
    "        elif idx == 2:\n",
    "            model = load_model(cfg['model_pth'], cfg['backbone'])\n",
    "\n",
    "        else:\n",
    "            model = Net(cfg)    \n",
    "            model = torch.nn.DataParallel(model).cuda()\n",
    "            model.load_state_dict(torch.load(cfg['model_pth'], map_location=torch.device('cpu'))['model'])\n",
    "\n",
    "    if cfg['tta']:\n",
    "        if ensemple_type == \"mine\":\n",
    "            model = tta.SegmentationTTAWrapper(model, tta.aliases.flip_transform(), merge_mode='mean')\n",
    "        else:\n",
    "            if idx <= 2:\n",
    "                model = tta.SegmentationTTAWrapper(model, tta.aliases.hflip_transform(), merge_mode='mean')\n",
    "            else:\n",
    "                model = tta.SegmentationTTAWrapper(model, tta.aliases.flip_transform(), merge_mode='mean')\n",
    "\n",
    "    \n",
    "    preds = []\n",
    "    masks_ = []\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "    \n",
    "    for index, (images, masks) in enumerate(tqdm(valid_loader)):  \n",
    "        images  = images.to(device, dtype=torch.float)\n",
    "        masks  = masks.to(device, dtype=torch.float)\n",
    "        if cfg['img_size'][0] != 256:\n",
    "            masks = torch.nn.functional.interpolate(masks, size=256, mode='nearest') \n",
    "            \n",
    "        masks_.append(torch.squeeze(masks, dim=1))\n",
    "\n",
    "        with torch.inference_mode():\n",
    "            images = torch.nn.functional.interpolate(images,size=cfg['img_size'][0], mode='nearest')\n",
    "            pred = model(images)                     \n",
    "            pred = torch.nn.functional.interpolate(pred.sigmoid(), size=256, mode='nearest') \n",
    "            preds.append(torch.squeeze(pred, dim=1))\n",
    "\n",
    "                  \n",
    "    del model, pred, images, masks\n",
    "    torch.cuda.empty_cache()\n",
    "    gc.collect()\n",
    "            \n",
    "    model_masks = torch.cat(masks_, dim=0)\n",
    "    model_preds = torch.cat(preds, dim=0)    \n",
    "    \n",
    "#     model_masks = torch.flatten(model_masks, start_dim=0, end_dim=1)\n",
    "#     model_preds = torch.flatten(model_preds, start_dim=0, end_dim=1)  \n",
    "    \n",
    "    final_preds.append(model_preds)\n",
    "    final_masks.append(model_masks)\n",
    "    \n",
    "#     #####\n",
    "#     best_threshold = 0.0\n",
    "#     best_dice_score = 0.0\n",
    "#     for threshold in [i / 100 for i in range(101)] :\n",
    "#         score = dice_coef(model_masks, model_preds, thr=threshold).cpu().detach().numpy() \n",
    "#         if score > best_dice_score:\n",
    "#             best_dice_score = score\n",
    "#             best_threshold = threshold\n",
    "\n",
    "\n",
    "#     print(best_dice_score, best_threshold)\n",
    "#     final_preds.append(model_preds)\n",
    "    \n",
    "    \n",
    "    \n",
    "#     torch.save(model_preds, f\"../../output/final_preds/{cfg['call_sign']}.pt\")\n",
    "#     if idx == 0:\n",
    "#         torch.save(model_preds, f\"../../output/final_preds/{cfg['call_sign']}_{idx}.pt\")\n",
    "\n",
    "\n",
    "\n",
    "# best_threshold = 0.0\n",
    "# best_dice_score = 0.0\n",
    "# for threshold in [i / 100 for i in range(101)] :\n",
    "#     score = dice_coef(model_masks, model_preds.sigmoid(), thr=threshold).cpu().detach().numpy() \n",
    "#     if score > best_dice_score:\n",
    "#         best_dice_score = score\n",
    "#         best_threshold = threshold\n",
    "\n",
    "\n",
    "# print(best_dice_score, best_threshold)\n",
    "# final_preds.append(model_preds)\n",
    "\n",
    "# del model\n",
    "# torch.cuda.empty_cache()\n",
    "# gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5622a4dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# final_preds[0].shape, final_preds[1].shape, final_preds[2].shape, final_preds[3].shape, final_preds[4].shape\n",
    "\n",
    "final_preds = torch.cat(final_preds, dim=0)\n",
    "final_preds = torch.flatten(final_preds, start_dim=0, end_dim=1)  \n",
    "\n",
    "\n",
    "final_masks = torch.cat(final_masks, dim=0)\n",
    "final_masks = torch.flatten(final_masks, start_dim=0, end_dim=1)  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "21c1dae7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([3438592, 256]), torch.Size([3438592, 256]))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_masks.shape, final_preds.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3cc19d74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# score = dice_coef(final_masks, final_preds, thr=0.4).cpu().detach().numpy() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4f76a77",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "55f0f51e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6910231 0.39\n"
     ]
    }
   ],
   "source": [
    "# final_preds = torch.stack(final_preds).mean(dim=0)\n",
    "\n",
    "best_threshold = 0.0\n",
    "best_dice_score = 0.0\n",
    "for threshold in [i / 100 for i in range(101)] :\n",
    "    score = dice_coef(final_masks, final_preds, thr=threshold).cpu().detach().numpy() \n",
    "    if score > best_dice_score:\n",
    "        best_dice_score = score\n",
    "        best_threshold = threshold\n",
    "\n",
    "\n",
    "print(best_dice_score, best_threshold)\n",
    "# final_preds.append(model_preds)\n",
    "\n",
    "# del model\n",
    "# torch.cuda.empty_cache()\n",
    "# gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c0f95cbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# final_preds = torch.stack(final_preds).mean(dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "fc34b857",
   "metadata": {},
   "outputs": [],
   "source": [
    "# final_preds = [\n",
    "#     torch.load(f\"../../output/final_preds/roh_1_00.pt\"),\n",
    "#     torch.load(f\"../../output/final_preds/roh_1_01.pt\"),\n",
    "#     torch.load(f\"../../output/final_preds/roh_1_02.pt\"),\n",
    "#     torch.load(f\"../../output/final_preds/roh_1_03.pt\")\n",
    "# ]\n",
    "\n",
    "# final_preds = torch.stack(final_preds).mean(dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35113965",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08ee16a6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b057f6ff",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "stack expects each tensor to be equal size, but got [1856, 256, 256] at entry 0 and [3712, 256, 256] at entry 1",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[23], line 12\u001b[0m\n\u001b[1;32m      1\u001b[0m masks_ \u001b[38;5;241m=\u001b[39m [torch\u001b[38;5;241m.\u001b[39mload(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m../../output/final_preds/roh_1_00_0.pt\u001b[39m\u001b[38;5;124m\"\u001b[39m)]\n\u001b[1;32m      3\u001b[0m preds \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m      4\u001b[0m     torch\u001b[38;5;241m.\u001b[39mload(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m../../output/final_preds/roh_1_00.pt\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m      5\u001b[0m     torch\u001b[38;5;241m.\u001b[39mload(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m../../output/final_preds/roh_1_01.pt\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m      8\u001b[0m     torch\u001b[38;5;241m.\u001b[39mload(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m../../output/final_preds/roh_1_04.pt\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m      9\u001b[0m ]\n\u001b[0;32m---> 12\u001b[0m final_preds \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstack\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpreds\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mmean(dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: stack expects each tensor to be equal size, but got [1856, 256, 256] at entry 0 and [3712, 256, 256] at entry 1"
     ]
    }
   ],
   "source": [
    "masks_ = [torch.load(f\"../../output/final_preds/roh_1_00_0.pt\")]\n",
    "\n",
    "preds = [\n",
    "    torch.load(f\"../../output/final_preds/roh_1_00.pt\"),\n",
    "    torch.load(f\"../../output/final_preds/roh_1_01.pt\"),\n",
    "    torch.load(f\"../../output/final_preds/roh_1_02.pt\"),\n",
    "    torch.load(f\"../../output/final_preds/roh_1_03.pt\"),\n",
    "    torch.load(f\"../../output/final_preds/roh_1_04.pt\"),\n",
    "]\n",
    "\n",
    "\n",
    "final_preds = torch.stack(preds).mean(dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c8d0160",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6ec1cd9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fb96f90a",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "The size of tensor a (1146368) must match the size of tensor b (3438848) at non-singleton dimension 0",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 12\u001b[0m\n\u001b[1;32m     10\u001b[0m best_dice_score \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.0\u001b[39m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m threshold \u001b[38;5;129;01min\u001b[39;00m [i \u001b[38;5;241m/\u001b[39m \u001b[38;5;241m100\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m101\u001b[39m)] :\n\u001b[0;32m---> 12\u001b[0m     score \u001b[38;5;241m=\u001b[39m \u001b[43mdice_coef\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_masks\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel_preds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mthr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mthreshold\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mnumpy() \n\u001b[1;32m     13\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m score \u001b[38;5;241m>\u001b[39m best_dice_score:\n\u001b[1;32m     14\u001b[0m         best_dice_score \u001b[38;5;241m=\u001b[39m score\n",
      "Cell \u001b[0;32mIn[8], line 4\u001b[0m, in \u001b[0;36mdice_coef\u001b[0;34m(y_true, y_pred, thr, epsilon)\u001b[0m\n\u001b[1;32m      2\u001b[0m y_true \u001b[38;5;241m=\u001b[39m y_true\u001b[38;5;241m.\u001b[39mto(torch\u001b[38;5;241m.\u001b[39mfloat32)\n\u001b[1;32m      3\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m (y_pred\u001b[38;5;241m>\u001b[39mthr)\u001b[38;5;241m.\u001b[39mto(torch\u001b[38;5;241m.\u001b[39mfloat32)\n\u001b[0;32m----> 4\u001b[0m inter \u001b[38;5;241m=\u001b[39m (\u001b[43my_true\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43my_pred\u001b[49m)\u001b[38;5;241m.\u001b[39msum()\n\u001b[1;32m      5\u001b[0m den \u001b[38;5;241m=\u001b[39m y_true\u001b[38;5;241m.\u001b[39msum() \u001b[38;5;241m+\u001b[39m y_pred\u001b[38;5;241m.\u001b[39msum()\n\u001b[1;32m      6\u001b[0m dice \u001b[38;5;241m=\u001b[39m ((\u001b[38;5;241m2\u001b[39m\u001b[38;5;241m*\u001b[39minter\u001b[38;5;241m+\u001b[39mepsilon)\u001b[38;5;241m/\u001b[39m(den\u001b[38;5;241m+\u001b[39mepsilon))\u001b[38;5;241m.\u001b[39mmean()\n",
      "\u001b[0;31mRuntimeError\u001b[0m: The size of tensor a (1146368) must match the size of tensor b (3438848) at non-singleton dimension 0"
     ]
    }
   ],
   "source": [
    "model_masks = torch.cat(masks_, dim=0)\n",
    "model_preds = torch.cat(preds[:2], dim=0)\n",
    "\n",
    "model_masks = torch.flatten(model_masks, start_dim=0, end_dim=1)\n",
    "model_preds = torch.flatten(model_preds, start_dim=0, end_dim=1)  \n",
    "\n",
    "\n",
    "\n",
    "best_threshold = 0.0\n",
    "best_dice_score = 0.0\n",
    "for threshold in [i / 100 for i in range(101)] :\n",
    "    score = dice_coef(model_masks, model_preds, thr=threshold).cpu().detach().numpy() \n",
    "    print(score, threshold)\n",
    "    if score > best_dice_score:\n",
    "        best_dice_score = score\n",
    "        best_threshold = threshold\n",
    "\n",
    "\n",
    "print(best_dice_score, best_threshold)\n",
    "final_preds.append(model_preds)\n",
    "\n",
    "del model\n",
    "torch.cuda.empty_cache()\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd920086",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c527e166",
   "metadata": {},
   "outputs": [
    {
     "ename": "OutOfMemoryError",
     "evalue": "CUDA out of memory. Tried to allocate 5.47 GiB (GPU 0; 23.69 GiB total capacity; 21.86 GiB already allocated; 240.19 MiB free; 22.20 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[18], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mmodel_preds\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msigmoid\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 5.47 GiB (GPU 0; 23.69 GiB total capacity; 21.86 GiB already allocated; 240.19 MiB free; 22.20 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF"
     ]
    }
   ],
   "source": [
    "# model_preds.sigmoid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "dc81fed5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_masks = torch.load(\"../../output/final_preds/val_masks.pt\")\n",
    "\n",
    "# model_names = [\"nir_01\", \"nir_02\", \"nir_03\", \"roh_01\", \"roh_02\", \"roh_03\", \"roh_04\", \"roh_05\", \"roh_06\", \"roh_07\",  ]\n",
    "# old_preds = []\n",
    "# for name in tqdm(model_names, total=len(model_names)):\n",
    "#     old_preds.append(torch.load(f\"../../output/final_preds/{name}.pt\"))\n",
    "\n",
    "# if len(final_preds) > 0:\n",
    "#     final_preds.extend(old_preds)\n",
    "# else:\n",
    "#     final_preds = old_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69bee834",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81770165",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d3df7d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# score = dice_coef(model_masks, final_preds[0], thr=0.5).cpu().detach().numpy() # get_score(labels, preds) \n",
    "# score\n",
    "\n",
    "# 0.65458226 0.83\n",
    "# 0.6572782 0.1\n",
    "\n",
    "len(final_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "190a8772",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1d72a60",
   "metadata": {},
   "outputs": [],
   "source": [
    "def boost_dice(params, TH=None):    \n",
    "    for index, val in enumerate(params.keys()):\n",
    "        if index == 0:            \n",
    "            preds = params[val]*final_preds[0]\n",
    "        else:\n",
    "            preds += params[val]*final_preds[index]\n",
    "    \n",
    "    \n",
    "    param_sum = 0\n",
    "    for key, val in params.items():\n",
    "        param_sum += val\n",
    "\n",
    "    preds = preds/param_sum\n",
    "    \n",
    "    \n",
    "    if TH:\n",
    "        best_threshold = TH\n",
    "        preds1 = (preds.sigmoid()).double()            \n",
    "        best_score = dice_coef(model_masks, preds1, thr=best_threshold).cpu().detach().numpy() # get_score(labels, preds) \n",
    "    else:\n",
    "        best_threshold = 0.0\n",
    "        best_score = 0.0\n",
    "        for threshold in [i / 100 for i in range(101)] :    \n",
    "            preds1 = (preds.sigmoid()>threshold).double()            \n",
    "            score = dice_coef(model_masks, preds1, thr=threshold).cpu().detach().numpy() # get_score(labels, preds) \n",
    "            if score > best_score:\n",
    "                best_score = score\n",
    "                best_threshold = threshold\n",
    "            \n",
    "#     best_score = score\n",
    "#     best_threshold = threshold\n",
    "    return best_score, best_threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fda1d51",
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(trial):\n",
    "    TH = None\n",
    "    \n",
    "    params = {}    \n",
    "    for i in range(len(final_preds)):\n",
    "        params[f\"w{i+1}\"] = trial.suggest_float(f'w{i+1}', 0, 1) \n",
    "        \n",
    "        \n",
    "    score, best_threshold  = boost_dice(params, TH=TH)\n",
    "    params['threshold'] = best_threshold\n",
    "    if not TH:\n",
    "        print(params)\n",
    "    return score\n",
    "\n",
    "study = optuna.create_study(direction='maximize')\n",
    "# study = optuna.create_study(direction='minimize')\n",
    "\n",
    "study.optimize(objective, n_trials=1500)\n",
    "\n",
    "best_params = study.best_params\n",
    "best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "55a2c9fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# [I 2023-06-16 19:56:17,542] | TH:0.11 | Trial 2772 finished with value: 0.685997724533081 and parameters: {'w1': 0.2728695549458137, 'w2': 0.32228366602907965, 'w3': 0.5198602860436105, 'w4': 0.3645111903670712, 'w5': 0.9222454111482654, 'w6': 0.513409920082969, 'w7': 0.8675021234700891, 'w8': 0.0722146925058941, 'w9': 0.09988548514924554, 'w10': 0.04023375737773327}. Best is trial 2772 with value: 0.685997724533081.\n",
    "\n",
    "#  th:0.10 | Best is trial 665 with value: 0.686022162437439.\n",
    "# {'w1': 0.07249514832914417,\n",
    "#  'w2': 0.3044527524365949,\n",
    "#  'w3': 0.46339624897419424,\n",
    "#  'w4': 0.30916961792390085,\n",
    "#  'w5': 0.9820263596044505,\n",
    "#  'w6': 0.13629275856955803,\n",
    "#  'w7': 0.9819243920033219,\n",
    "#  'w8': 0.10786742006569568,\n",
    "#  'w9': 0.017963370847088496,\n",
    "#  'w10': 0.2269773365337288}\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# th:0.09 Trial 599 finished with value: 0.6861019730567932 and parameters: {'w1': 0.08411983424429813, 'w2': 0.2397144985551996, 'w3': 0.565597681400598, 'w4': 0.27365134829998194, 'w5': 0.8519007002554051, 'w6': 0.0034467714906157854, 'w7': 0.9632070992690323, 'w8': 0.036223969967080535, 'w9': 0.1408041912398369, 'w10': 0.0808046168343181}. Best is trial 599 with value: 0.6861019730567932.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Best is trial 979 th:0.08 | with value: 0.6860898733139038.\n",
    "# {'w1': 0.04219070925378117,\n",
    "#  'w2': 0.2814610861485835,\n",
    "#  'w3': 0.45306132583945036,\n",
    "#  'w4': 0.08300507686599938,\n",
    "#  'w5': 0.9689922153717234,\n",
    "#  'w6': 0.5832699926479489,\n",
    "#  'w7': 0.8380073187640669,\n",
    "#  'w8': 0.00027139503974531664,\n",
    "#  'w9': 0.08843006287891712,\n",
    "#  'w10': 0.2639847795838674}\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# 0.6835659742355347 and parameters: {'w1': 0.012511663696378001, 'w2': 0.7308678705489249, 'w3': 0.7309363859834449, 'w4': 0.8998292052691779, 'w5': 0.9377896156028775}. Best is trial 183 with value: 0.6835659742355347.\n",
    "# TH: 0.1\n",
    "\n",
    "# pl3_round2_s2 included at last\n",
    "# Trial 177 finished with value: 0.6850342154502869 and parameters: \n",
    "#{'w1': 0.1976000599839957, 'w2': 0.4126970697935236, 'w3': 0.0010400328806771247, 'w4': 0.13358923329787326, 'w5': 0.6293367385421876, 'w6': 0.8157294847307331}. Best is trial 1286 with value: 0.6850342154502869.\n",
    "#TH:0.19\n",
    "\n",
    "\n",
    "# 0.6850342154502869\n",
    "# {'w1': 0.1976000599839957,\n",
    "#  'w2': 0.4126970697935236,\n",
    "#  'w3': 0.0010400328806771247,\n",
    "#  'w4': 0.13358923329787326,\n",
    "#  'w5': 0.6293367385421876,\n",
    "#  'w6': 0.8157294847307331}\n",
    "\n",
    "\n",
    "\n",
    "#  0.6864011883735657 and parameters: \n",
    "# {'w1': 0.0037528376744131176, 'w2': 0.1968372043477828, 'w3': 0.324173594919189,\n",
    "#  'w4': 0.08069037545373889, 'w5': 0.666119680919894, 'w6': 0.23792233503063126, 'w7': 0.6474738231385013, \n",
    "#  }\n",
    "#. Best is trial 301 with value: 0.6864011883735657.\n",
    "# TH: 0.11\n",
    "\n",
    "\n",
    "\n",
    "#th: 0.2\n",
    "# {'w1': 0.9118427143017789, 'w2': 0.07722806128805348, 'w3': 0.3483576258941602}\n",
    "\n",
    "\n",
    "# 0.6802493929862976\n",
    "# {'w1': 0.901456237984701,\n",
    "#  'w2': 0.03333500127663481,\n",
    "#  'w3': 0.1012744451767772,\n",
    "#  'w4': 0.3315684160625839}\n",
    "\n",
    "\n",
    "# 0.6802645325660706\n",
    "# {'w1': 0.9423043059931125,\n",
    "#  'w2': 0.12999481950972483,\n",
    "#  'w3': 0.34096541343299724}\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# 0.6753096580505371\n",
    "# {'w1': 0.8191544364616984,\n",
    "#  'w2': 0.2172873170900641,\n",
    "#  'w3': 0.9872223348463418,\n",
    "#  'w4': 0.34763898831692425,\n",
    "#  'w5': 0.6106201134139329}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6f44e04",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edbe34be",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03dd0179",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe1cc496",
   "metadata": {},
   "outputs": [],
   "source": [
    "# {'w1': 0.19193466652838265, 'w2': 0.0010692529855302647, 'w3': 0.19479657217496682, 'w4': 0.7062431810854415, 'threshold': 0.39}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab67a95d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  0.66671222448349 and parameters:\n",
    "# {'w1': 0.7800660379809229, 'w2': 0.5851307264271756, 'w3': 0.5728701966485974}\n",
    "# threshold: 0.32\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e63a6b39",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ed33dce",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec9790b8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "id": "7e7891cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pretrainedmodels\n",
    "\n",
    "def conv3x3(in_channel, out_channel): #not change resolusion\n",
    "    return nn.Conv2d(in_channel,out_channel,\n",
    "                      kernel_size=3,stride=1,padding=1,dilation=1,bias=False)\n",
    "\n",
    "def conv1x1(in_channel, out_channel): #not change resolution\n",
    "    return nn.Conv2d(in_channel,out_channel,\n",
    "                      kernel_size=1,stride=1,padding=0,dilation=1,bias=False)\n",
    "\n",
    "def init_weight(m):\n",
    "    classname = m.__class__.__name__\n",
    "    if classname.find('Conv') != -1:\n",
    "        #nn.init.xavier_uniform_(m.weight, gain=1)\n",
    "        #nn.init.xavier_normal_(m.weight, gain=1)\n",
    "        #nn.init.kaiming_uniform_(m.weight, mode='fan_in', nonlinearity='relu')\n",
    "        nn.init.kaiming_normal_(m.weight, mode='fan_in', nonlinearity='relu')\n",
    "        #nn.init.orthogonal_(m.weight, gain=1)\n",
    "        if m.bias is not None:\n",
    "            m.bias.data.zero_()\n",
    "    elif classname.find('Batch') != -1:\n",
    "        m.weight.data.normal_(1,0.02)\n",
    "        m.bias.data.zero_()\n",
    "    elif classname.find('Linear') != -1:\n",
    "        nn.init.orthogonal_(m.weight, gain=1)\n",
    "        if m.bias is not None:\n",
    "            m.bias.data.zero_()\n",
    "    elif classname.find('Embedding') != -1:\n",
    "        nn.init.orthogonal_(m.weight, gain=1)\n",
    "    \n",
    "\n",
    "class ChannelAttentionModule(nn.Module):\n",
    "    def __init__(self, in_channel, reduction):\n",
    "        super().__init__()\n",
    "        self.global_maxpool = nn.AdaptiveMaxPool2d(1)\n",
    "        self.global_avgpool = nn.AdaptiveAvgPool2d(1) \n",
    "        self.fc = nn.Sequential(\n",
    "            conv1x1(in_channel, in_channel//reduction).apply(init_weight),\n",
    "            nn.ReLU(True),\n",
    "            conv1x1(in_channel//reduction, in_channel).apply(init_weight)\n",
    "        )\n",
    "        \n",
    "    def forward(self, inputs):\n",
    "        x1 = self.global_maxpool(inputs)\n",
    "        x2 = self.global_avgpool(inputs)\n",
    "        x1 = self.fc(x1)\n",
    "        x2 = self.fc(x2)\n",
    "        x  = torch.sigmoid(x1 + x2)\n",
    "        return x\n",
    "    \n",
    "    \n",
    "class SpatialAttentionModule(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv3x3 = conv3x3(2,1).apply(init_weight)\n",
    "        \n",
    "    def forward(self, inputs):\n",
    "        x1,_ = torch.max(inputs, dim=1, keepdim=True)\n",
    "        x2 = torch.mean(inputs, dim=1, keepdim=True)\n",
    "        x  = torch.cat([x1,x2], dim=1)\n",
    "        x  = self.conv3x3(x)\n",
    "        x  = torch.sigmoid(x)\n",
    "        return x\n",
    "    \n",
    "    \n",
    "class CBAM(nn.Module):\n",
    "    def __init__(self, in_channel, reduction):\n",
    "        super().__init__()\n",
    "        self.channel_attention = ChannelAttentionModule(in_channel, reduction)\n",
    "        self.spatial_attention = SpatialAttentionModule()\n",
    "        \n",
    "    def forward(self, inputs):\n",
    "        x = inputs * self.channel_attention(inputs)\n",
    "        x = x * self.spatial_attention(x)\n",
    "        return x\n",
    "    \n",
    "    \n",
    "class CenterBlock(nn.Module):\n",
    "    def __init__(self, in_channel, out_channel):\n",
    "        super().__init__()\n",
    "        self.conv = conv3x3(in_channel, out_channel).apply(init_weight)\n",
    "        \n",
    "    def forward(self, inputs):\n",
    "        x = self.conv(inputs)\n",
    "        return x\n",
    "\n",
    "\n",
    "class DecodeBlock(nn.Module):\n",
    "    def __init__(self, in_channel, out_channel, upsample):\n",
    "        super().__init__()\n",
    "        self.bn1 = nn.BatchNorm2d(in_channel).apply(init_weight)\n",
    "        self.upsample = nn.Sequential()\n",
    "        if upsample:\n",
    "            self.upsample.add_module('upsample',nn.Upsample(scale_factor=2, mode='nearest'))\n",
    "        self.conv3x3_1 = conv3x3(in_channel, in_channel).apply(init_weight)\n",
    "        self.bn2 = nn.BatchNorm2d(in_channel).apply(init_weight)\n",
    "        self.conv3x3_2 = conv3x3(in_channel, out_channel).apply(init_weight)\n",
    "        self.cbam = CBAM(out_channel, reduction=16)\n",
    "        self.conv1x1   = conv1x1(in_channel, out_channel).apply(init_weight)\n",
    "        \n",
    "    def forward(self, inputs):\n",
    "        x  = F.relu(self.bn1(inputs))\n",
    "        x  = self.upsample(x)\n",
    "        x  = self.conv3x3_1(x)\n",
    "        x  = self.conv3x3_2(F.relu(self.bn2(x)))\n",
    "        x  = self.cbam(x)\n",
    "        x += self.conv1x1(self.upsample(inputs)) #shortcut\n",
    "        return x\n",
    " \n",
    "            \n",
    "#U-Net SeResNext101 + CBAM + hypercolumns + deepsupervision\n",
    "class UNET_SERESNEXT101(nn.Module):\n",
    "    def __init__(self, resolution, deepsupervision, clfhead, clf_threshold, load_weights=True):\n",
    "        super().__init__()\n",
    "        h,w = resolution\n",
    "        self.deepsupervision = deepsupervision\n",
    "        self.clfhead = clfhead\n",
    "        self.clf_threshold = clf_threshold\n",
    "        \n",
    "        #encoder\n",
    "        model_name = 'se_resnext101_32x4d'\n",
    "        if load_weights:\n",
    "            seresnext101 = pretrainedmodels.__dict__[model_name](pretrained='imagenet')\n",
    "        else:\n",
    "            seresnext101 = pretrainedmodels.__dict__[model_name](pretrained=None)\n",
    "        \n",
    "        self.encoder0 = nn.Sequential(\n",
    "            seresnext101.layer0.conv1, #(*,3,h,w)->(*,64,h/2,w/2)\n",
    "            seresnext101.layer0.bn1,\n",
    "            seresnext101.layer0.relu1,\n",
    "        )\n",
    "        self.encoder1 = nn.Sequential(\n",
    "            seresnext101.layer0.pool, #->(*,64,h/4,w/4)\n",
    "            seresnext101.layer1 #->(*,256,h/4,w/4)\n",
    "        )\n",
    "        self.encoder2 = seresnext101.layer2 #->(*,512,h/8,w/8)\n",
    "        self.encoder3 = seresnext101.layer3 #->(*,1024,h/16,w/16)\n",
    "        self.encoder4 = seresnext101.layer4 #->(*,2048,h/32,w/32)\n",
    "        \n",
    "        #center\n",
    "        self.center  = CenterBlock(2048,512) #->(*,512,h/32,w/32)\n",
    "        \n",
    "        #decoder\n",
    "        self.decoder4 = DecodeBlock(512+2048,64, upsample=True) #->(*,64,h/16,w/16)\n",
    "        self.decoder3 = DecodeBlock(64+1024,64, upsample=True) #->(*,64,h/8,w/8)\n",
    "        self.decoder2 = DecodeBlock(64+512,64,  upsample=True) #->(*,64,h/4,w/4) \n",
    "        self.decoder1 = DecodeBlock(64+256,64,   upsample=True) #->(*,64,h/2,w/2) \n",
    "        self.decoder0 = DecodeBlock(64,64, upsample=True) #->(*,64,h,w) \n",
    "        \n",
    "        #upsample\n",
    "        self.upsample4 = nn.Upsample(scale_factor=16, mode='bilinear', align_corners=True)\n",
    "        self.upsample3 = nn.Upsample(scale_factor=8, mode='bilinear', align_corners=True)\n",
    "        self.upsample2 = nn.Upsample(scale_factor=4, mode='bilinear', align_corners=True)\n",
    "        self.upsample1 = nn.Upsample(scale_factor=2, mode='bilinear', align_corners=True)\n",
    "        \n",
    "        #deep supervision\n",
    "        self.deep4 = conv1x1(64,1).apply(init_weight)\n",
    "        self.deep3 = conv1x1(64,1).apply(init_weight)\n",
    "        self.deep2 = conv1x1(64,1).apply(init_weight)\n",
    "        self.deep1 = conv1x1(64,1).apply(init_weight)\n",
    "        \n",
    "        #final conv\n",
    "        self.final_conv = nn.Sequential(\n",
    "            conv3x3(320,64).apply(init_weight),\n",
    "            nn.ELU(True),\n",
    "            conv1x1(64,1).apply(init_weight)\n",
    "        )\n",
    "        \n",
    "        #clf head\n",
    "        self.avgpool = nn.AdaptiveAvgPool2d(1)\n",
    "        self.clf = nn.Sequential(\n",
    "            nn.BatchNorm1d(2048).apply(init_weight),\n",
    "            nn.Linear(2048,512).apply(init_weight),\n",
    "            nn.ELU(True),\n",
    "            nn.BatchNorm1d(512).apply(init_weight),\n",
    "            nn.Linear(512,1).apply(init_weight)\n",
    "        )\n",
    "        \n",
    "        \n",
    "    def forward(self, inputs):\n",
    "        #encoder\n",
    "        x0 = self.encoder0(inputs) #->(*,64,h/2,w/2)\n",
    "        x1 = self.encoder1(x0) #->(*,256,h/4,w/4)\n",
    "        x2 = self.encoder2(x1) #->(*,512,h/8,w/8)\n",
    "        x3 = self.encoder3(x2) #->(*,1024,h/16,w/16)\n",
    "        x4 = self.encoder4(x3) #->(*,2048,h/32,w/32)\n",
    "        \n",
    "        #clf head\n",
    "        logits_clf = self.clf(self.avgpool(x4).squeeze(-1).squeeze(-1)) #->(*,1)\n",
    "        if (not self.training) & (self.clf_threshold is not None):\n",
    "            if (torch.sigmoid(logits_clf)>self.clf_threshold).sum().item()==0:\n",
    "                bs,_,h,w = inputs.shape\n",
    "                logits = torch.zeros((bs,1,h,w))\n",
    "                if self.clfhead:\n",
    "                    if self.deepsupervision:\n",
    "                        return logits,_,_\n",
    "                    else:\n",
    "                        return logits,_\n",
    "                else:\n",
    "                    if self.deepsupervision:\n",
    "                        return logits,_\n",
    "                    else:\n",
    "                        return logits\n",
    "        \n",
    "        #center\n",
    "        y5 = self.center(x4) #->(*,320,h/32,w/32)\n",
    "        \n",
    "        #decoder\n",
    "        y4 = self.decoder4(torch.cat([x4,y5], dim=1)) #->(*,64,h/16,w/16)\n",
    "        y3 = self.decoder3(torch.cat([x3,y4], dim=1)) #->(*,64,h/8,w/8)\n",
    "        y2 = self.decoder2(torch.cat([x2,y3], dim=1)) #->(*,64,h/4,w/4)\n",
    "        y1 = self.decoder1(torch.cat([x1,y2], dim=1)) #->(*,64,h/2,w/2) \n",
    "        y0 = self.decoder0(y1) #->(*,64,h,w)\n",
    "        \n",
    "        #hypercolumns\n",
    "        y4 = self.upsample4(y4) #->(*,64,h,w)\n",
    "        y3 = self.upsample3(y3) #->(*,64,h,w)\n",
    "        y2 = self.upsample2(y2) #->(*,64,h,w)\n",
    "        y1 = self.upsample1(y1) #->(*,64,h,w)\n",
    "        hypercol = torch.cat([y0,y1,y2,y3,y4], dim=1)\n",
    "        \n",
    "        #final conv\n",
    "        logits = self.final_conv(hypercol) #->(*,1,h,w)\n",
    "        \n",
    "        if self.clfhead:\n",
    "            if self.deepsupervision:\n",
    "                s4 = self.deep4(y4)\n",
    "                s3 = self.deep3(y3)\n",
    "                s2 = self.deep2(y2)\n",
    "                s1 = self.deep1(y1)\n",
    "                logits_deeps = [s4,s3,s2,s1]\n",
    "                return logits, logits_deeps, logits_clf\n",
    "            else:\n",
    "                return logits, logits_clf\n",
    "        else:\n",
    "            if self.deepsupervision:\n",
    "                s4 = self.deep4(y4)\n",
    "                s3 = self.deep3(y3)\n",
    "                s2 = self.deep2(y2)\n",
    "                s1 = self.deep1(y1)\n",
    "                logits_deeps = [s4,s3,s2,s1]\n",
    "                return logits, logits_deeps\n",
    "            else:\n",
    "                return logits\n",
    "            \n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "id": "7eed6aca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(model_name, resolution, deepsupervision, clfhead, clf_threshold, load_weights):\n",
    "    if model_name=='seresnext101':\n",
    "        model = UNET_SERESNEXT101(resolution, deepsupervision, clfhead, clf_threshold, load_weights)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "id": "27a3505e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ssl\n",
    "ssl._create_default_https_context = ssl._create_unverified_context\n",
    "\n",
    "\n",
    "model = build_model(\"seresnext101\", (256,256), False, False, 0.5, load_weights=True )\n",
    "# model.cuda()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "id": "831f24ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "id": "3d341ac4",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.ones(64, 3, 256, 256)\n",
    "out = model(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "id": "31c6cce1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([64, 1, 256, 256])"
      ]
     },
     "execution_count": 224,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44a1bdfd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
